<!doctype html><html lang=en-us><script src=https://code.jquery.com/jquery-3.6.0.min.js></script><script>$(document).ready(function(){$("#mode").on("click",updateDiagramImage),updateDiagramImage()});function updateDiagramImage(){const e=$("html").attr("data-dark-mode")!==void 0;console.debug("Dark mode:",e);const t=e?"-dark":"-light";$(".schema").each(function(){const n=$(this);let e=n.attr("src");e=e.replace(/(-dark|-light)\.svg$/,""),n.attr("src",e+t+".svg")})}</script><head><meta charset=utf-8><title>Architectural Design | PositionPal</title>
<meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Architectural design of the system."><meta name=keywords content="Documentation,Hugo,Hugo Theme,Bootstrap"><meta name=author content="Colin Wilson - Lotus Labs"><meta name=email content="support@aigis.uk"><meta name=website content="https://lotusdocs.dev"><meta name=Version content="v0.1.0"><link rel=icon href=https://position-pal.github.io/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://position-pal.github.io/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://position-pal.github.io/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://position-pal.github.io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://position-pal.github.io/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://position-pal.github.io/site.webmanifest><meta property="og:title" content="Architectural Design"><meta property="og:description" content="Architectural design of the system."><meta property="og:type" content="website"><meta property="og:url" content="https://position-pal.github.io/docs/3-arch-design/"><meta property="og:image" content="https://position-pal.github.io/opengraph/card-base-2_hu_711a68e18c3eb542.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://position-pal.github.io/opengraph/card-base-2_hu_711a68e18c3eb542.png"><meta name=twitter:title content="Architectural Design"><meta name=twitter:description content="Architectural design of the system."><link rel=alternate type=application/atom+xml title="Atom feed for PositionPal" href=/index.xml><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><script type=text/javascript src=https://position-pal.github.io/docs/js/flexsearch.bundle.min.f5159d5a2151ffbb653996ec17eaff7da4e04c286bd879fc41839d36a5586f3f20eaead0b6089de48f9adc669cdee771.js integrity=sha384-9RWdWiFR/7tlOZbsF+r/faTgTChr2Hn8QYOdNqVYbz8g6urQtgid5I+a3Gac3udx crossorigin=anonymous></script><link rel=stylesheet href=/docs/scss/style.min.9f03e981e3c58ca6d2bea6054d9b016bda03bdea30dab992a9ed960a485547da4f733d8e380d198907912f36918f1157.css integrity=sha384-nwPpgePFjKbSvqYFTZsBa9oDveow2rmSqe2WCkhVR9pPcz2OOA0ZiQeRLzaRjxFX crossorigin=anonymous></head><body><div class=content><div class="page-wrapper toggled"><nav id=sidebar class=sidebar-wrapper><div class=sidebar-brand><a href=/ aria-label=HomePage alt=HomePage><svg id="Layer_1" viewBox="0 0 250 250"><path d="m143 39.5c-18 0-18 18-18 18s0-18-18-18H22c-2.76.0-5 2.24-5 5v143c0 2.76 2.24 5 5 5h76c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h76c2.76.0 5-2.24 5-5V44.5c0-2.76-2.24-5-5-5h-85zM206 163c0 1.38-1.12 2.5-2.5 2.5H143c-18 0-18 18-18 18s0-18-18-18H46.5c-1.38.0-2.5-1.12-2.5-2.5V69c0-1.38 1.12-2.5 2.5-2.5H98c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h51.5c1.38.0 2.5 1.12 2.5 2.5v94z" style="fill:#06f"/></svg></a></div><div class=sidebar-content style="height:calc(100% - 131px)"><ul class=sidebar-menu><li><a class=sidebar-root-link href=https://position-pal.github.io/docs/1-introduction/introduction/><i class="material-icons me-2">Emoji_Objects</i>
Introduction</a></li><li class=sidebar-dropdown><button class=btn>
<i class="material-icons me-2">Engineering</i>
Domain Analysis</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/2-domain-analysis/1-functional-requirements/>Functional Requirements</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/2-domain-analysis/2-business-requirements/>Business Requirements</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/2-domain-analysis/3-quality-attributes/>Quality Attributes</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/2-domain-analysis/4-event-storming/>Event Storming</a></li></ul></div></li><li class="sidebar-dropdown current active"><button class=btn>
<i class="material-icons me-2">Location_City</i>
Architectural Design</button><div class="sidebar-submenu d-block"><ul><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/3-arch-design/1-bounded-contexts/>Bounded Contexts</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/3-arch-design/2-architecture-design/>Architecture Design</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/3-arch-design/4-patterns/>Architectural Patterns</a></li></ul></div></li><li class=sidebar-dropdown><button class=btn>
<i class="material-icons me-2">Construction</i>
Detailed Design</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/4-detailed-design/0-overall-architecture/>Big Picture</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/4-detailed-design/1-shared-kernel/>Shared Kernel design</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/4-detailed-design/5-user-groups-service/>User and Group Service design</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/4-detailed-design/2-location-service/>Location Service design</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/4-detailed-design/4-chat-service/>Chat Service design</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/4-detailed-design/3-notification-service/>Notification Service design</a></li></ul></div></li><li class=sidebar-dropdown><button class=btn>
<i class="material-icons me-2">Code</i>
Implementation Details</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/5-implementation/0-common/>Implementation details for common services</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/5-implementation/4-user-groupd-service/>User and Group Service implementation details</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/5-implementation/1-location-service/>Location Service implementation details</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/5-implementation/3-chat-service/>Chat Service implementation details</a></li><li><a class=sidebar-nested-link href=https://position-pal.github.io/docs/5-implementation/2-notification-service/>Notification Service implementation details</a></li></ul></div></li><li><a class=sidebar-root-link href=https://position-pal.github.io/docs/6-validation/validation/><i class="material-icons me-2">Bug_Report</i>
Self Assessment and Validation</a></li><li><a class=sidebar-root-link href=https://position-pal.github.io/docs/7-devops/devops/><i class="material-icons me-2">Rocket_Launch</i>
DevOps</a></li><li><a class=sidebar-root-link href=https://position-pal.github.io/docs/8-deployment/deployment/><i class="material-icons me-2">Rocket_Launch</i>
Deployment</a></li><li><a class=sidebar-root-link href=https://position-pal.github.io/docs/9-conclusions/conclusions/><i class="material-icons me-2">Pin_Drop</i>
Conclusions</a></li></ul></div><ul class="sidebar-footer list-unstyled mb-0"></ul></nav><main class="page-content bg-transparent"><div id=top-header class="top-header d-print-none"><div class="header-bar d-flex justify-content-between"><div class="d-flex align-items-center"><a href=/ class="logo-icon me-3" aria-label=HomePage alt=HomePage><div class=small><svg id="Layer_1" viewBox="0 0 250 250"><path d="m143 39.5c-18 0-18 18-18 18s0-18-18-18H22c-2.76.0-5 2.24-5 5v143c0 2.76 2.24 5 5 5h76c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h76c2.76.0 5-2.24 5-5V44.5c0-2.76-2.24-5-5-5h-85zM206 163c0 1.38-1.12 2.5-2.5 2.5H143c-18 0-18 18-18 18s0-18-18-18H46.5c-1.38.0-2.5-1.12-2.5-2.5V69c0-1.38 1.12-2.5 2.5-2.5H98c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h51.5c1.38.0 2.5 1.12 2.5 2.5v94z" style="fill:#06f"/></svg></div><div class=big><svg id="Layer_1" viewBox="0 0 250 250"><path d="m143 39.5c-18 0-18 18-18 18s0-18-18-18H22c-2.76.0-5 2.24-5 5v143c0 2.76 2.24 5 5 5h76c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h76c2.76.0 5-2.24 5-5V44.5c0-2.76-2.24-5-5-5h-85zM206 163c0 1.38-1.12 2.5-2.5 2.5H143c-18 0-18 18-18 18s0-18-18-18H46.5c-1.38.0-2.5-1.12-2.5-2.5V69c0-1.38 1.12-2.5 2.5-2.5H98c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h51.5c1.38.0 2.5 1.12 2.5 2.5v94z" style="fill:#06f"/></svg></div></a><button id=close-sidebar class="btn btn-icon btn-soft">
<span class="material-icons size-20 menu-icon align-middle">menu</span>
</button>
<button id=flexsearch-button class="ms-3 btn btn-soft" data-bs-toggle=collapse data-bs-target=#FlexSearchCollapse aria-expanded=false aria-controls=FlexSearchCollapse>
<span class="material-icons size-20 menu-icon align-middle">search</span>
<span class="flexsearch-button-placeholder ms-1 me-2 d-none d-sm-block">Search</span><div class="d-none d-sm-block"><span class=flexsearch-button-keys><kbd class=flexsearch-button-cmd-key><svg width="44" height="15"><path d="M2.118 11.5A1.519 1.519.0 011 11.042 1.583 1.583.0 011 8.815a1.519 1.519.0 011.113-.458h.715V6.643h-.71A1.519 1.519.0 011 6.185 1.519 1.519.0 01.547 5.071 1.519 1.519.0 011 3.958 1.519 1.519.0 012.118 3.5a1.519 1.519.0 011.114.458A1.519 1.519.0 013.69 5.071v.715H5.4V5.071A1.564 1.564.0 016.976 3.5 1.564 1.564.0 018.547 5.071 1.564 1.564.0 016.976 6.643H6.261V8.357h.715a1.575 1.575.0 011.113 2.685 1.583 1.583.0 01-2.227.0A1.519 1.519.0 015.4 9.929V9.214H3.69v.715a1.519 1.519.0 01-.458 1.113A1.519 1.519.0 012.118 11.5zm0-.857a.714.714.0 00.715-.714V9.214H2.118a.715.715.0 100 1.429zm4.858.0a.715.715.0 100-1.429H6.261v.715a.714.714.0 00.715.714zM3.69 8.357H5.4V6.643H3.69zM2.118 5.786h.715V5.071a.714.714.0 00-.715-.714.715.715.0 00-.5 1.22A.686.686.0 002.118 5.786zm4.143.0h.715a.715.715.0 00.5-1.22.715.715.0 00-1.22.5z" fill="currentcolor"/><path d="M12.4 11.475H11.344l3.879-7.95h1.056z" fill="currentcolor"/><path d="M25.073 5.384l-.864.576a2.121 2.121.0 00-1.786-.923 2.207 2.207.0 00-2.266 2.326 2.206 2.206.0 002.266 2.325 2.1 2.1.0 001.782-.918l.84.617a3.108 3.108.0 01-2.622 1.293 3.217 3.217.0 01-3.349-3.317 3.217 3.217.0 013.349-3.317A3.046 3.046.0 0125.073 5.384z" fill="currentcolor"/><path d="M30.993 5.142h-2.07v5.419H27.891V5.142h-2.07V4.164h5.172z" fill="currentcolor"/><path d="M34.67 4.164c1.471.0 2.266.658 2.266 1.851.0 1.087-.832 1.809-2.134 1.855l2.107 2.691h-1.28L33.591 7.87H33.07v2.691H32.038v-6.4zm-1.6.969v1.8h1.572c.832.0 1.22-.3 1.22-.918s-.411-.882-1.22-.882z" fill="currentcolor"/><path d="M42.883 10.561H38.31v-6.4h1.033V9.583h3.54z" fill="currentcolor"/></svg>
</kbd><kbd class=flexsearch-button-key><svg width="15" height="15"><path d="M5.926 12.279H4.41L9.073 2.721H10.59z" fill="currentcolor"/></svg></kbd></span></div></button></div><div class="d-flex align-items-center"><ul class="list-unstyled mb-0"></ul><button id=mode class="btn btn-icon btn-default ms-2" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg height="30" width="30" viewBox="0 0 48 48" fill="currentcolor"><title>Enable dark mode</title><path d="M24 42q-7.5.0-12.75-5.25T6 24t5.25-12.75T24 6q.4.0.85.025.45.025 1.15.075-1.8 1.6-2.8 3.95t-1 4.95q0 4.5 3.15 7.65Q28.5 25.8 33 25.8q2.6.0 4.95-.925T41.9 22.3q.05.6.075.975Q42 23.65 42 24q0 7.5-5.25 12.75T24 42zm0-3q5.45.0 9.5-3.375t5.05-7.925q-1.25.55-2.675.825Q34.45 28.8 33 28.8q-5.75.0-9.775-4.025T19.2 15q0-1.2.25-2.575t.9-3.125q-4.9 1.35-8.125 5.475Q9 18.9 9 24q0 6.25 4.375 10.625T24 39zm-.2-14.85z"/></svg>
</span><span class=toggle-light><svg height="30" width="30" viewBox="0 0 48 48" fill="currentcolor"><title>Enable light mode</title><path d="M24 31q2.9.0 4.95-2.05T31 24t-2.05-4.95T24 17t-4.95 2.05T17 24t2.05 4.95T24 31zm0 3q-4.15.0-7.075-2.925T14 24t2.925-7.075T24 14t7.075 2.925T34 24t-2.925 7.075T24 34zM3.5 25.5q-.65.0-1.075-.425Q2 24.65 2 24t.425-1.075Q2.85 22.5 3.5 22.5h5q.65.0 1.075.425Q10 23.35 10 24t-.425 1.075T8.5 25.5zm36 0q-.65.0-1.075-.425Q38 24.65 38 24t.425-1.075T39.5 22.5h5q.65.0 1.075.425Q46 23.35 46 24t-.425 1.075-1.075.425zM24 10q-.65.0-1.075-.425Q22.5 9.15 22.5 8.5v-5q0-.65.425-1.075Q23.35 2 24 2t1.075.425T25.5 3.5v5q0 .65-.425 1.075Q24.65 10 24 10zm0 36q-.65.0-1.075-.425T22.5 44.5v-5q0-.65.425-1.075Q23.35 38 24 38t1.075.425.425 1.075v5q0 .65-.425 1.075Q24.65 46 24 46zM12 14.1l-2.85-2.8q-.45-.45-.425-1.075.025-.625.425-1.075.45-.45 1.075-.45t1.075.45L14.1 12q.4.45.4 1.05.0.6-.4 1-.4.45-1.025.45T12 14.1zm24.7 24.75L33.9 36q-.4-.45-.4-1.075t.45-1.025q.4-.45 1-.45t1.05.45l2.85 2.8q.45.45.425 1.075-.025.625-.425 1.075-.45.45-1.075.45t-1.075-.45zM33.9 14.1q-.45-.45-.45-1.05.0-.6.45-1.05l2.8-2.85q.45-.45 1.075-.425.625.025 1.075.425.45.45.45 1.075t-.45 1.075L36 14.1q-.4.4-1.025.4t-1.075-.4zM9.15 38.85q-.45-.45-.45-1.075t.45-1.075L12 33.9q.45-.45 1.05-.45.6.0 1.05.45.45.45.45 1.05.0.6-.45 1.05l-2.8 2.85q-.45.45-1.075.425-.625-.025-1.075-.425zM24 24z"/></svg></span></button></div></div><div class=collapse id=FlexSearchCollapse><div class=flexsearch-container><div class=flexsearch-keymap><li><kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8m3-3-3 3-3-3"/></g></svg></kbd>
<kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8m3 3-3-3-3 3"/></g></svg></kbd>
<span class=flexsearch-key-label>to navigate</span></li><li><kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4m3 3-3-3 3-3"/></g></svg></kbd>
<span class=flexsearch-key-label>to select</span></li><li><kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993.0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016s1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5s-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864.0 1.6425 1.031 1.5443 2.2492h-2.956"/></g></svg></kbd>
<span class=flexsearch-key-label>to close</span></li></div><form class="flexsearch position-relative flex-grow-1 ms-2 me-2"><div class="d-flex flex-row"><input id=flexsearch class=form-control type=search placeholder=Search aria-label=Search autocomplete=off>
<button id=hideFlexsearch type=button class="ms-2 btn btn-soft">
cancel</button></div><div id=suggestions class="shadow rounded-1 d-none"></div></form></div></div></div><div class=container-fluid><div class=layout-spacing><div class="d-md-flex justify-content-between align-items-center"><nav aria-label=breadcrumb class="d-inline-block pb-2 mt-1 mt-sm-0"><ul id=breadcrumbs class="breadcrumb bg-transparent mb-0" itemscope itemtype=https://schema.org/BreadcrumbList><li class="breadcrumb-item text-capitalize active" aria-current=page itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=/docs/><i class="material-icons size-20 align-text-bottom" itemprop=name>Home</i>
</a><meta itemprop=position content='1'></li><li class="breadcrumb-item text-capitalize active" itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><span itemprop=name>Architectural Design</span>
<meta itemprop=position content='2'></li></ul></nav></div><div class="row flex-xl-nowrap"><div class="docs-toc col-xl-3 visually-hidden visually-hidden d-xl-block"><toc><div class="fw-bold text-uppercase mb-2">On this page</div><nav id=TableOfContents></nav></toc></div><div class="docs-toc-mobile visually-hidden visually-hidden d-print-none d-xl-none"><button id=toc-dropdown-btn class="btn-secondary dropdown-toggle" type=button data-bs-toggle=dropdown data-bs-offset=0,0 aria-expanded=false>
Table of Contents</button><nav id=toc-mobile></nav></div><div class="docs-content col-12 mt-0"><div class="mb-0 d-flex"><h1 class="content-title mb-0">Architectural Design</h1></div><div id=content class=main-content><div class="row flex-xl-wrap"><div id=list-item class="col-md-4 col-12 mt-4 pt-2"><a class="text-decoration-none text-reset" href=https://position-pal.github.io/docs/3-arch-design/1-bounded-contexts/><div class="card h-100 features feature-full-bg rounded p-4 position-relative overflow-hidden border-1"><span class="icon-color d-flex my-3"><i class="material-icons align-middle">article</i></span><div class="card-body p-0 content"><p class="fs-5 fw-semibold card-title mb-1">Bounded Contexts</p><p class="para card-text mb-0"></p></div></div></a></div><div id=list-item class="col-md-4 col-12 mt-4 pt-2"><a class="text-decoration-none text-reset" href=https://position-pal.github.io/docs/3-arch-design/2-architecture-design/><div class="card h-100 features feature-full-bg rounded p-4 position-relative overflow-hidden border-1"><span class="icon-color d-flex my-3"><i class="material-icons align-middle">article</i></span><div class="card-body p-0 content"><p class="fs-5 fw-semibold card-title mb-1">Architecture Design</p><p class="para card-text mb-0"></p></div></div></a></div><div id=list-item class="col-md-4 col-12 mt-4 pt-2"><a class="text-decoration-none text-reset" href=https://position-pal.github.io/docs/3-arch-design/4-patterns/><div class="card h-100 features feature-full-bg rounded p-4 position-relative overflow-hidden border-1"><span class="icon-color d-flex my-3"><i class="material-icons align-middle">article</i></span><div class="card-body p-0 content"><p class="fs-5 fw-semibold card-title mb-1">Architectural Patterns</p><p class="para card-text mb-0"></p></div></div></a></div></div></div><div><hr class=doc-hr><div id=doc-nav class=d-print-none></div></div></div></div></div></div><footer class="shadow py-3 d-print-none"><div class=container-fluid><div class="row align-items-center"><div class=col><div class="text-sm-start text-center mx-md-2"><p class=mb-0></p></div></div></div></div></footer></main></div></div><button onclick=topFunction() id=back-to-top aria-label="Back to Top Button" class="back-to-top fs-5"><svg width="24" height="24"><path d="M12 10.224l-6.3 6.3-1.38-1.372L12 7.472l7.68 7.68-1.38 1.376z" style="fill:#fff"/></svg></button>
<script>(()=>{var e=document.getElementById("mode");e!==null&&(window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{e.matches?(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")):(localStorage.setItem("theme","light"),document.documentElement.removeAttribute("data-dark-mode"))}),e.addEventListener("click",()=>{document.documentElement.toggleAttribute("data-dark-mode"),localStorage.setItem("theme",document.documentElement.hasAttribute("data-dark-mode")?"dark":"light")}),localStorage.getItem("theme")==="dark"?document.documentElement.setAttribute("data-dark-mode",""):document.documentElement.removeAttribute("data-dark-mode"))})()</script><script src=/docs/js/bootstrap.c7927bdd82eceb076739257add3f4b0e11379da037c07d5c7110daeb6de0e3edcb2de867604550f88815157e4ec4ddb7.js integrity=sha384-x5J73YLs6wdnOSV63T9LDhE3naA3wH1ccRDa623g4+3LLehnYEVQ+IgVFX5OxN23 defer></script><script type=text/javascript src=https://position-pal.github.io/docs/js/bundle.min.4b07706b1da436c9600e641a8cf51af20b3e497ead85e0d0af7552a0314e8e317dc63bb69d12c072092518621478900d.js integrity=sha384-Swdwax2kNslgDmQajPUa8gs+SX6theDQr3VSoDFOjjF9xju2nRLAcgklGGIUeJAN crossorigin=anonymous defer></script><script type=module>
    var suggestions = document.getElementById('suggestions');
    var search = document.getElementById('flexsearch');

    const flexsearchContainer = document.getElementById('FlexSearchCollapse');

    const hideFlexsearchBtn = document.getElementById('hideFlexsearch');

    const configObject = { toggle: false }
    const flexsearchContainerCollapse = new Collapse(flexsearchContainer, configObject) 

    if (search !== null) {
        document.addEventListener('keydown', inputFocus);
        flexsearchContainer.addEventListener('shown.bs.collapse', function () {
            search.focus();
        });
        
        var topHeader = document.getElementById("top-header");
        document.addEventListener('click', function(elem) {
            if (!flexsearchContainer.contains(elem.target) && !topHeader.contains(elem.target))
                flexsearchContainerCollapse.hide();
        });
    }

    hideFlexsearchBtn.addEventListener('click', () =>{
        flexsearchContainerCollapse.hide()
    })

    function inputFocus(e) {
        if (e.ctrlKey && e.key === '/') {
            e.preventDefault();
            flexsearchContainerCollapse.toggle();
        }
        if (e.key === 'Escape' ) {
            search.blur();
            
            flexsearchContainerCollapse.hide();
        }
    };

    document.addEventListener('click', function(event) {

    var isClickInsideElement = suggestions.contains(event.target);

    if (!isClickInsideElement) {
        suggestions.classList.add('d-none');
    }

    });

    


    document.addEventListener('keydown',suggestionFocus);

    function suggestionFocus(e) {
    const suggestionsHidden = suggestions.classList.contains('d-none');
    if (suggestionsHidden) return;

    const focusableSuggestions= [...suggestions.querySelectorAll('a')];
    if (focusableSuggestions.length === 0) return;

    const index = focusableSuggestions.indexOf(document.activeElement);

    if (e.key === "ArrowUp") {
        e.preventDefault();
        const nextIndex = index > 0 ? index - 1 : 0;
        focusableSuggestions[nextIndex].focus();
    }
    else if (e.key === "ArrowDown") {
        e.preventDefault();
        const nextIndex= index + 1 < focusableSuggestions.length ? index + 1 : index;
        focusableSuggestions[nextIndex].focus();
    }

    }

    


    (function(){

    var index = new FlexSearch.Document({
        
        tokenize: "forward",
        minlength:  0 ,
        cache:  100 ,
        optimize:  true ,
        document: {
        id: 'id',
        store: [
            "href", "title", "description"
        ],
        index: ["title", "description", "content"]
        }
    });


    


    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    


    

    

    index.add(
            {
                id:  0 ,
                href: "\/docs\/1-introduction\/introduction\/",
                title: "Introduction",
                description: "What, Why, and How",
                content: "\nWhat is PositionPal? linkPositionPal is a micro-services-based application for creating groups of trusted users with whom to share location, routes, and notify of dangerous or emergency situation to create an effective and timely service and support network.\nThe idea comes from some news read recently about young people who, on their way home at night in unsafe areas of the city, share their location in a WhatsApp group of users to support and watch each other.\nThe Problem linkPersonal safety concerns are increasingly significant in urban environments, especially for those traveling alone at night or through unfamiliar areas. While general-purpose messaging apps like WhatsApp allow basic location sharing, they lack specialized safety features and automation that could make the difference in emergency situations.\nOur Solution linkPositionPal transforms the ad-hoc “text when you get home” practice into a comprehensive safety system with features specifically designed for personal security:\nTrusted Groups: Create circles of trusted friends, family members, or colleagues Real-time Location Sharing: Share your precise location with selected groups Route Tracking: Set expected routes and arrival times Automated Alerts: Generate notifications when deviating from planned routes or not reaching destinations on time Emergency Notifications: Quick access to alert trusted contacts in dangerous situations Privacy Controls: Fine-grained permissions for when and with whom your location is shared Getting Started linkThe following sections will guide you through the setup, architecture, and usage of PositionPal, demonstrating how it can become an essential tool in your personal safety toolkit.\n"
            }
        );
    index.add(
            {
                id:  1 ,
                href: "\/docs\/2-domain-analysis\/",
                title: "Domain Analysis",
                description: "Knowledge crunching",
                content: ""
            }
        );
    index.add(
            {
                id:  2 ,
                href: "\/docs\/2-domain-analysis\/1-functional-requirements\/",
                title: "Functional Requirements",
                description: "In this section are collected the functional requirements of the system in the form of User Stories.\nUser Stories linkUsers Management link As a new user I want to register with the system using my details So that I can access the application’s features\nAs a registered user I want to log in with my credentials So that I can access my account and use the application\nAs a logged user I want to update my profile information So that I can keep my personal details current\n",
                content: "In this section are collected the functional requirements of the system in the form of User Stories.\nUser Stories linkUsers Management link As a new user I want to register with the system using my details So that I can access the application’s features\nAs a registered user I want to log in with my credentials So that I can access my account and use the application\nAs a logged user I want to update my profile information So that I can keep my personal details current\nAs a logged user I want to delete my profile So that I can remove my data from the system when I no longer wish to use it\nGroup Management link As a registered user I want to create a new group by specifying the name So that I can later go and interact with it As a group member I want to add one or more users to this existing group So they can be displayed in the member list As a group member I want to remove one or more users from this existing group So they can no longer be displayed in the member list As a group member I want to leave the group So I can no longer be displayed in the member list As a group member I want to update the group name So I can change it Location tracking link As a logged user I want to be able to start sharing my location with other groups’ member So that I’m able to be monitored\nAs a logged user who is sharing their position with a set of groups I want to be able to stop sharing it with a group’s members So that I can go where I want without letting know those member\nAs a logged user I want to be able to receive location updates from my groups’ members who are sharing their location So that I can view their live location on a map in real-time\nAs a logged user I want to be able to get the last known location and state of my groups’ member So that I can see their last reported location and status when live sharing is unavailable\nAs a logged user I want to be able to send an SOS alert comprising of my location to all members of all groups I’m participating despite the fact I’m or not sharing my location So that if I am in a dangerous situation my friends are notified and knows where I am\nAs a logged user I want to start sharing my location to all groups’ members after the trigger of an SOS alert So that my live location is automatically shared after an SOS alert to aid responders\nAs a logged user who is sharing their position I want to be able to share a journey towards a location specifying the time by which I’ll be there So that my friends know where I’m going\nAs a logged user who is sharing a journey I want to be able to trigger an SOS alert So that if I am in a dangerous situation my friends are notified\nAs a logged user in SOS mode I want to be able to stop the SOS So that my friend are notified I’m not anymore in danger\nAs a logged user who is sharing a journey I want to be able to stop it prematurely So that my friend knows a change in my plan have occurred\nAs a logged user I want to be able to see the entire path taken by my groups’ members who are sharing a journey or triggered an SOS alert So that I know where they have been during the dangerous situation\nAs a logged user I want to be able to receive a notification when one of my groups’ member start a journey or trigger an SOS alert So that I’m aware of it\nAs a logged user I want to be able to receive a notification if one my groups’ member who triggered an SOS alert goes offline or deactivate it So that I can take appropriate action\nAs a logged user I want to be able to receive a notification if one my groups’ member who started a journey stops moving, doesn’t arrive on time, goes offline, reaches their destination or deactivate it So that I can take appropriate action\nChat link As a logged user I want to connecto to a group So that I can communicate with other group members\nAs a group member I want to send a message to the group So that I can communicate with other group members\nAs a group member I want to disconnect from the group So that I can no longer communicate with other group members Acceptance tests linkFollowing BDD principles, starting from the above user stories, a set of acceptance test specifications have been defined. These specifications are written in Gherkin using Cucumber, providing a structured and human-readable format that facilitates communication between stakeholders, even for those who have not a technical background. Moreover, they serve end-to-end tests, ensuring that the system meets the defined requirements while aligning with end users’ expectations and needs (see the Validation section for more details about tests). By leveraging this approach, the tests remain clear, maintainable, and closely tied to business objectives.\nUser Management link Scenario: Register a New User Given that the user is not yet registered When registering with valid details Then the system successfully registers the user Scenario: Login with Valid Credentials Given logged user with the correct email and password When system returns a valid authentication token Then authentication token can be use to authorize requests Scenario: Update User Profile Given new user logged in When updating the profile information Then the system successfully updates the user data When requesting the deletion of the user profile Then the system deletes the user data and confirms the deletion Location tracking link Feature: Users real-time tracking Background: Given I am a logged user * with a registered device And I am in a group with other users Scenario: User can track other users in their groups in real-time When I access my group tracking information Then I should see the real-time location of online group members And the last known location of offline group members Scenario: User is able to share their location with other group members When I start sharing my location Then my last known location should be updated And my state should be `Active` Scenario: User can stop sharing their location with other group members When I stop sharing my location with that group Then the group's members should not see my location anymore * my state should be updated to `Inactive` But my last known location should still be available Feature: Users routes tracking Background: Given I am a logged user * with a registered device And I am in a group with other users Scenario: User can activate a route that is recorded and visible to group members When I activate the routing mode indicating a destination and the ETA Then my state is updated to `Routing` * my group's members receive a notification indicating I've started a routing And my group's members can see the route I've been taken since activating routing mode Scenario Outline: A route can be stopped Given I'm in routing mode When Then the routing is stopped * the route discarded * my state is updated to `Active` And my group's members receive a notification indicating Examples: | event | | I have arrived at the destination | | I have stopped the routing | Scenario Outline: Route notifications Given I'm in routing mode When Then my group's members receive a notification indicating Examples: | event | | I have gone offline | | I have not arrived by the estimated time | | I have been stuck in the same position for a while | "
            }
        );
    index.add(
            {
                id:  3 ,
                href: "\/docs\/2-domain-analysis\/2-business-requirements\/",
                title: "Business Requirements",
                description: "Glossary link??\nUse cases linkUsers and Groups Management link User Management Use Cases link Register with the system\nActor: User Description: A new user creates an account in the system. Preconditions: The user has not previously registered with the system. Main Scenario: The user provides required registration information (name, surname, email and password); The system validates the provided information; The system creates a new user account; Alternative Scenario: Registration information is invalid The system notifies the user about validation errors; The user corrects the information and resubmits. Postcondition: The user has a registered account in the system. Log in with my credentials\n",
                content: "Glossary link??\nUse cases linkUsers and Groups Management link User Management Use Cases link Register with the system\nActor: User Description: A new user creates an account in the system. Preconditions: The user has not previously registered with the system. Main Scenario: The user provides required registration information (name, surname, email and password); The system validates the provided information; The system creates a new user account; Alternative Scenario: Registration information is invalid The system notifies the user about validation errors; The user corrects the information and resubmits. Postcondition: The user has a registered account in the system. Log in with my credentials\nActor: User Description: A registered user authenticates to access the system. Preconditions: The user has a registered account in the system. Main Scenario: The user enters their credentials (email and password); The system validates the credentials; The system grants access to the user and creates an authenticated session. Alternative Scenario: Invalid credentials The system notifies the user that the credentials are incorrect; The user re-enters the correct credentials. Postcondition: The user is authenticated and can access restricted functionalities. Update my profile information\nActor: Authenticated User Description: An authenticated user modifies their personal information in the system. Preconditions: The user is logged in to the system. Main Scenario: The user accesses their profile settings; The user modifies the desired information (name, surname and password); The user confirms the changes; The system validates and saves the updated information. Alternative Scenario: Invalid information The system notifies the user about validation errors; The user corrects the information and resubmits. Postcondition: The user’s profile information is updated in the system. Log out\nActor: Authenticated User Description: An authenticated user ends their current session. Preconditions: The user is logged in to the system. Main Scenario: The user selects the logout option; The system terminates the user’s authenticated session; The system redirects the user to the unauthenticated state. Postcondition: The user is no longer authenticated and cannot access restricted functionalities. Group Management Use Cases link Create a new group\nActor: Authenticated User Description: An authenticated user creates a new group in the system. Preconditions: The user is logged in to the system. Main Scenario: The user selects the option to create a new group; The user provides the group name; The system creates the new group with the user as the initial member; The system confirms the successful creation of the group. Postcondition: A new group exists in the system with the user as a member. Add one user to a group\nActor: Authenticated User Description: An authenticated user adds another user to a group. Preconditions: The user is logged in to the system; The user is a member of the group; The target user exists in the system. Main Scenario: The user selects the group they want to add a user to; The user enters the email of the user they want to add; The user confirms adding the selected user to the group; The system adds the selected user as a member of the group; The system notifies both users about the addition. Alternative Scenario: The target user is already a member The system notifies the user that the target is already a group member. Postcondition: The target user is now a member of the group. Remove one user from a group\nActor: Authenticated User Description: An authenticated user removes another user from a group. Preconditions: The user is logged in to the system; The user is a member of the group; The target user is a member of the group. Main Scenario: The user selects the group they want to remove a user from; The user selects the group member to remove; The user confirms removing the selected user from the group; The system removes the selected user’s membership from the group; Postcondition: The target user is no longer a member of the group. Leave a group\nActor: Authenticated User Description: An authenticated user leaves a group they belong to. Preconditions: The user is logged in to the system; The user is a member of the group. Main Scenario: The user selects the group they want to leave; The user confirms leaving the group; The system removes the user’s membership from the group; Postcondition: The user is no longer a member of the group. Update the group name\nActor: Authenticated User Description: An authenticated user changes the name of a group. Preconditions: The user is logged in to the system; The user is a member of the group. Main Scenario: The user selects the group they want to rename; The user enters a new name for the group; The user confirms the name change; The system updates the group name; Postcondition: The group now has the new name in the system. Location Tracking link Start Location Sharing\nActor: Group member Description: The user starts sharing their location with members of one or more groups. Preconditions: The user is logged and is a member of the group they want to share their location with. Main Scenario: The user selects the group they want to share their location with; The user starts sharing their location with members of that group; A visual feedback is sent to the user notifying them the location sharing has started. Postcondition: The user’s location is shared with the selected group members. Stop Location Sharing\nActor: Group member Description: The user stops sharing their location with members of one or more groups. Preconditions: The user is logged and is a member of the group they want to stop sharing their location with; The user is currently sharing their location. Main Scenario: The user selects the group they want to stop sharing their location with; The user stops sharing their location; A visual feedback is sent to the user notifying them the location sharing has been turned off; Postcondition: The user’s location is no longer shared with the selected group members. Send a GPS Location Update\nActor: Group member Description: The user sends a GPS location update to the system for a specific set of groups. Preconditions: The user is logged and is a member of the group they want to send the location to; Main Scenario: The user sends a GPS location update; The system updates the user’s location. Alternative Scenario: The user have triggered the SOS The user sends a GPS location update; The system updates the user’s location and their path in SOS mode. Alternative Scenario: The user is sharing a journey. The user sends a GPS location update; The system updates the user’s location and the path of the journey; The system verify if the user have reached the destination. If so, stops the journey sharing, otherwise it continues; The system verify if the user is stuck or the ETA is elapsed. If so, trigger a notification for all group members. Postcondition: The user’s location is updated server-side and their state is ‘Active’. View Real-time Group Members’ Locations and State on a Map\nActor: Group member Description: The user views the real-time locations and state of group members on a map. Preconditions: The user is logged and is a member of the group they want to view. Main Scenario: The user selects the group they want to view; The user views the real-time locations and state of all group members on a map. Trigger SOS Alert\nActor: Group member description: The user triggers an SOS alert because they are in danger. Preconditions: The user is logged and is part of at least one group; The user is not already in SOS mode. Main Scenario: The user triggers the SOS alert; The system updates the user’s location and enters SOS mode, starting recording their path; The system sends a notification to all group members. Postcondition: The user is in ‘SOS’ mode. Stop SOS Mode\nActor: Group member Description: The user stops the SOS mode. Preconditions: The user is logged and is part of at least one group; The user is in SOS mode. Main Scenario: The user stops the SOS mode; The system stops recording the user’s path; The system sends a notification to all group members; Postcondition: The user is no longer in ‘SOS’ mode, but in ‘Active’ mode. Share a Journey\nActor: Group member description: The user start sharing a journey with a group; Preconditions: The user is logged and is part of the group they want to share the journey with; The user is not sharing a journey. Main Scenario: The user selects the group they want to share the journey with; The user starts sharing the journey by choosing the destination and the estimated time of arrival; The system sends a notification to all group members. Postcondition: The user is sharing the journey and their state is ‘Routing’. Stop Journey Sharing\nActor: Group member Description: The user stops sharing the journey. Preconditions: The user is logged and is part of the group they want to stop sharing the journey with; The user is sharing a journey. Main Scenario: The user selects the group they want to stop sharing the journey with; The user stops sharing the journey; The system sends a notification to all group members that the journey sharing has been stopped. Postcondition: The user is no longer sharing the journey and their state is ‘Active’. View Path of a Group Member on a Journey or in SOS Mode\nActor: Group member Description: The user views the path of a group member on a journey or in SOS mode. Preconditions: The user is logged and is part of the group they want to view the path of a group member; Main Scenario: The user selects the group they want to view the path of a group member; The user selects the group member they want to view the path of; The user views the path of the selected group member on a map. Postcondition: The user has viewed the path of the selected group member. "
            }
        );
    index.add(
            {
                id:  4 ,
                href: "\/docs\/2-domain-analysis\/3-quality-attributes\/",
                title: "Quality Attributes",
                description: "Quality Attributes (QA), also known as Non-Functional Requirements (NFR), are measurable properties of a system that describe its qualities and indicate how well it satisfies the needs of its stakeholders beyond the functional requirements.\nThese attributes play a crucial role in shaping the system architecture, as they influence design decisions, trade-offs, and the selection of appropriate technologies and patterns.\nIn the context of this project have been identified the following quality attributes that are considered essential for the success of system, divided into “Runtime” and “Development Time” categories:\n",
                content: "Quality Attributes (QA), also known as Non-Functional Requirements (NFR), are measurable properties of a system that describe its qualities and indicate how well it satisfies the needs of its stakeholders beyond the functional requirements.\nThese attributes play a crucial role in shaping the system architecture, as they influence design decisions, trade-offs, and the selection of appropriate technologies and patterns.\nIn the context of this project have been identified the following quality attributes that are considered essential for the success of system, divided into “Runtime” and “Development Time” categories:\nRuntime the system should be highly available and reliable to ensure users can access it when needed the system should be scalable to handle a growing number of users and data the system should be performant to provide a responsive user experience and minimize latency in critical operations the system should be secure to protect users’ data and privacy the system should be observable to allow monitoring and troubleshooting of its components in real-time the client application should be user-friendly to provide an intuitive and accessible interface for users to interact with the system Development Time the system should be testable to ensure the correctness of its behavior and facilitate maintenance over time; the system should be modular to allow independent development and streamlined deployment of its components; the system should be extensible to support future enhancements and integrations with other services without major refactoring or disruptions; the system should be maintainable to allow easy updates, bug fixes, and improvements over time without excessive effort or risk of regressions. Based on the above non-functional requirements, the team has identified the following scenarios to be considered during the design and implementation of the system.\nQuality Attributes Scenarios linkRuntime linkSecurity link Stimulus: An unauthorized access attempt is made to access sensitive data in the system. Stimulus Source: A malicious actor attempting to exploit potential vulnerabilities. Environment: The system operating in normal state in a production environment. Artifact: Authentication and authorization components. Response: The system blocks the access. Response Measure: ✅ Pass Condition: The system prevents 100% of unauthorized access attempts. ✅ Pass Condition: The system adheres to data privacy regulations by properly encrypting sensitive data at rest and in transit. Performance link Stimulus: A user performs a data-intensive operation on the system. Stimulus Source: User interacting with the system interface. Environment: The system operating under normal load in a production environment. Artifact: The specific service processing the request. Response: The system processes the request and returns the results efficiently. Response Measure: ✅ Pass Condition: 95 % of requests are under 1000ms and that 99% of requests are under 1500ms and the rate of requests failing is less than 0.05. ✅ Pass Condition: Resource utilization (CPU, memory) remains below 80% during peak load periods. User friendliness link Stimulus: A new user attempts to complete a core workflow in the system for the first time. Stimulus Source: First-time user. Environment: Production environment with final UI implementation. Artifact: Client application user interface. Response: The user is able to complete the workflow without external assistance. Response Measure: ✅ Pass Condition: 85% of new users complete core workflows successfully on first attempt without requiring help documentation. ✅ Pass Condition: UI responds to user interactions within 300ms to maintain the perception of immediate feedback. Observability link Stimulus: On or more services in the system is not responding as expected. Stimulus Source: Monitoring service detect and report the anomaly. Environment: The system operating in normal state in a production environment. Artifact: The monitoring service. Response: The monitoring service logs the anomaly and sends an alert to the system administrator. Response Measure: ✅ Pass Condition: The system administrator receives the alert in less than 1 minute. ✅ Pass Condition: The alert contains the service name, the error message, and the timestamp of the anomaly. ✅ Pass Condition: The alert is sent to the system administrator via email, a messaging service, or a dedicated monitoring platform. ✅ Pass Condition: The alert is logged in the monitoring system for future reference. Reliability link Stimulus: An error occurs in one of the system services. Stimulus Source: An exception (of any nature) is thrown inside a service program. Environment: The system operating in normal state in a production environment. Artifact: The affected service(s). Response: The infrastructure of the system automatically detects the failure and tries to restore the affected service(s), ensuring that no data is lost or corrupted. Response Measure: The service(s) returns to operate normally if they can be restored, otherwise they will be replaced by a new operational instance. ✅ Pass Condition: The system is able to restore the service(s) within 30 seconds. Availability link Stimulus: Due an internal error occurs, a service becomes unavailable. Stimulus Source: Hardware or network error. Environment: The system operating in normal state in a production environment. Artifact: The service that becomes unavailable. Response: The infrastructure of the system automatically detects the failure and tries to redirect the trafic in another replica if this is available, otherwise an error is reported to the monitoring system. Response Measure: ✅ Pass Condition: The system is able to redirect the traffic to another replica within 1 minute. Scalability link Stimulus: An huge amount of requests are performed to one or more services in the system. Stimulus Source: Users that tries to access the system. Environment: The system operating on an high load in a production environment. Artifact: Services of the system with huge amount of requests registered. Response: The infrastructure that hosts the system will automatically create new replicas of the services that are under high load, and will redirect the traffic to the new replicas. Response Measure: ✅ Pass Condition: System is able to serve all the requests with a response time of less than 3.5 second on the 98% of the requests. Development Time linkTestability link Source: Developer Stimulus: A new code change is submitted to the version control system Environment: In a controlled CI/CD pipeline with automated testing tools and environments set up Artifact: System modules and components Response: The system triggers all the automated test suite, comprising unit, integration, and end-to-end tests, to verify the correctness of the changes Response Measure: ✅ Pass Condition: All tests pass successfully withing 15 minutes ✅ Pass Condition: The test report must clearly indicate the tests report and any failed tests, including module name, error details and stack trace Modularity link Source: Development team Stimulus: A request is made to update, fix, or replace an existing module or component due to a bug fix, performance improvement, or internal refactoring. Environment: The system is operational and new code changes are being developed and tested in a controlled environment with all modules integrated Artifact: The specific component or module targeted for update or replacement Response: The requested module can be replaced or updated independently, using only its exposed APIs, without modifying or recompiling other modules. Response Measure: ✅ Pass Condition: Integration of the updated or new module must not require changes to other modules. ✅ Pass Condition: Integration testing must be completed within 20% of the original development effort for the module. ✅ Pass Condition: All tests for unchanged modules must pass after integration. Extensibility link Source: Product manager Stimulus: A request is made to add a new feature or integrate an external service that does not exist in the current system. Environment: During development, with the system operational for existing services, leveraging defined extension points or APIs. Artifact: New module or service to be integrated, extension points, and system interfaces. Response: The new feature must be implemented as a separate module using a clear and well-defined API, minimizing changes to existing code. The integration should not impact the performance or functionality of existing modules. Response Measure: ✅ Pass Condition: No more than 10% of the existing code can be modified to support the new module. ✅ Pass Condition: The new module must pass all tests independently before integration. ✅ Pass Condition: Integration must not degrade existing system performance by more than 5%. Maintainability link Source: Development team Stimulus: A bug is reported in a deployed module. Environment: In a controlled development environment with access to the source code, bug tracking system, and deployment tools. Artifact: System logs, bug report, and source code repository Response: The development team isolates the issue, applies a fix, and deploys it without affecting other modules. Response Measure: ✅ Pass Condition: No new regression failures are detected in automated tests post-deployment. "
            }
        );
    index.add(
            {
                id:  5 ,
                href: "\/docs\/2-domain-analysis\/4-event-storming\/",
                title: "Event Storming",
                description: "In order to extract the main functionality of the application as quickly and effectively as possible, Event Storming, a collaborative and visual modeling technique particularly used and valued in the agile and Domain-Driven development context, was used.\nIts power comes from a heterogeneous, multidisciplinary group of experts, from architects to product owners, via UI/UX designers to testers, who, together, collaborate to extract key features and the processes that drive them, sharing this knowledge so that it is shared beyond the compartments of each team. Moreover, this approach allows for uniformity in the language used (the ubiquitous language) and for raising and then resolving any ambiguities or misunderstandings that may arise early in the project.\n",
                content: "In order to extract the main functionality of the application as quickly and effectively as possible, Event Storming, a collaborative and visual modeling technique particularly used and valued in the agile and Domain-Driven development context, was used.\nIts power comes from a heterogeneous, multidisciplinary group of experts, from architects to product owners, via UI/UX designers to testers, who, together, collaborate to extract key features and the processes that drive them, sharing this knowledge so that it is shared beyond the compartments of each team. Moreover, this approach allows for uniformity in the language used (the ubiquitous language) and for raising and then resolving any ambiguities or misunderstandings that may arise early in the project.\nIt starts with a problem or objective and, through the use of colored stickynotes and markers, proceeds to map the processes and interactions between the various entities involved so as to obtain an overview of the system and its interactions. In more detail, the session begins with the identification of the domain events, that is, events related to the domain being explored that represent something interesting that has happened (past tense is used for this) and that may be useful for the system. These are arranged in temporal sequence so as to create a timeline representing the flow of events occurring in the system. This is followed by the identification of commands, i.e., actions that can be performed on the system by an actor, and policies by which the system reacts, going on to enrich the timeline by following the flow of events and actions. Finally, read models, or whatever information the system needs to show the user, are highlighted.\nGlossary:\nSticky note color Concept Description 🟨 Actor Person/user/personas. The actor who triggered the event / comamnd. 🟧 Domain Event An event that is interesting for the business. 🟦 Command An action that can be performed on the system. 🟪 Policy Capture reactive logic to events. 🟩 Read Model Information that the system needs to show the user. View details. 🏻 System An internal or external component of the application. 🟥 Hotspot An internal system constraint / some important note. As a result of the event storming session, the main core entities and aggregates of the system were identified and from those the bounded contexts were derived:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e "
            }
        );
    index.add(
            {
                id:  6 ,
                href: "\/docs\/3-arch-design\/",
                title: "Architectural Design",
                description: "Architectural design of the system.",
                content: ""
            }
        );
    index.add(
            {
                id:  7 ,
                href: "\/docs\/3-arch-design\/1-bounded-contexts\/",
                title: "Bounded Contexts",
                description: "Following the event storming session, the subsequent bounded contexts have been identified:\nUsers Management: it is responsible for managing the users’ lifecycle, from registration to deletion and the management of their profile information along with the authentication and authorization. Groups Management: it is responsible for managing the groups’ lifecycle, from creation to deletion, and the management of the group’s members. Location Tracking: it is responsible for managing the location tracking of the users, including the sharing of the location with groups’ members, the reception of location updates, thw sending of SOS alerts and the management of their paths. Notifications: it is responsible for managing the notifications, including the push notifications to the users’ devices. Chat: it is responsible for managing the chat between the users and the groups’ members. In the following sections, we will provide a detailed view of each bounded context, including its Ubiquitous Language, the Commands and the Events guiding the interactions between the different contexts. These can be categorized as Driving or Driven Events: the former are the events triggered by the user’s actions and that drives an application use case, while the latter are the events that are triggered by the system as a reaction to a use case or a system state change. Moreover we distinguish between Commands and Events to highlight the difference between a request to perform an action (Command) and the notification of something meaningful that has happened (Event):\n",
                content: "Following the event storming session, the subsequent bounded contexts have been identified:\nUsers Management: it is responsible for managing the users’ lifecycle, from registration to deletion and the management of their profile information along with the authentication and authorization. Groups Management: it is responsible for managing the groups’ lifecycle, from creation to deletion, and the management of the group’s members. Location Tracking: it is responsible for managing the location tracking of the users, including the sharing of the location with groups’ members, the reception of location updates, thw sending of SOS alerts and the management of their paths. Notifications: it is responsible for managing the notifications, including the push notifications to the users’ devices. Chat: it is responsible for managing the chat between the users and the groups’ members. In the following sections, we will provide a detailed view of each bounded context, including its Ubiquitous Language, the Commands and the Events guiding the interactions between the different contexts. These can be categorized as Driving or Driven Events: the former are the events triggered by the user’s actions and that drives an application use case, while the latter are the events that are triggered by the system as a reaction to a use case or a system state change. Moreover we distinguish between Commands and Events to highlight the difference between a request to perform an action (Command) and the notification of something meaningful that has happened (Event):\nUsers Management linkUbiquitous Language link Concept Description Synonyms User An individual who has registered and can access the system with a unique identity. Member, Account Holder Profile Collection of personal information and preferences associated with a user. User Profile Authentication The process of verifying a user’s identity, typically through credentials like email/password. Login, Sign-in Authorization Determination of what actions a user is permitted to perform within the system. Permissions, Access Control Credentials Information used to verify a user’s identity, such as email/password combinations or tokens. Login Details Session A period of time during which a user is actively authenticated in the system. User Session Registration The process by which a new user creates an account in the system. Sign-up, Account Creation Events link 🏷️ Event Type Event Name Description 🚀 Driving event UserRegistered Triggered when a new user successfully completes the registration process. UserAuthenticated Triggered when a user successfully logs into the system. UserLoggedOut Triggered when a user explicitly logs out of the system. ProfileUpdated Triggered when a user modifies their profile information. PasswordChanged Triggered when a user changes their password. 📥 Driven event UserCreated Notification that a new user account has been created in the system. AuthenticationFailed Notification of a failed authentication attempt. UserDeleted Notification that a user account has been permanently deleted from the system. Groups Management linkUbiquitous Language link Concept Description Synonyms Group A collection of users who are connected for shared tracking and communication purposes. Circle, Team Group Member A user who belongs to a group. Participant Events link 🏷️ Event Type Event Name Description 🚀 Driving event GroupCreated Triggered when a user creates a new group. 📥 Driven event GroupMemberAdded Triggered when a user is added to an existing group. GroupMemberRemoved Triggered when a member is removed from a group. Location Tracking linkUbiquitous Language link Concept Description Synonyms Location A specific point on a geographical plane, represented by coordinates that indicates where something / someone is located. Position Address A human-readable description of a location, usually including the street name, the city, the country, and the postal code along with the related location. ETA Estimated Time of Arrival, the time at which a user is expected to reach a certain destination. Route A set of positions that can be interpolated forming a path between two geographical positions. Path Tracking Represent the user route information at a certain point in time. State State of a user at a certain time, the values that it could assume are: online, offline, SOS, Routing, Warning. Session An aggregation of the user’s tracking information, the state and last location of a user in a certain period of time. Events link 🏷️ Event Type Event Name Description ClientJoinedToGroup The event triggered when a client join a group in order to start chat. ClientLeavedFromGroup The event triggered when a client leaves a group. ClientConnected The event sent from the client application when user logs in and is able to receive messages. ClientDisconnected The event sent from the client application when user logs out and is no longer reachable. Message The event sent from the client application when a new message is received in a group. Commands link Command Description DeleteGroup Delete a chat group. ClientJoinsGroup Add a new client in a group. ClientLeavesGroup Remove a client from a group. ClientConnects Make a client become available for receiving new messages. ClientDisconnects Make a client unavailable for receiving new messages. SendMessage Send a message in a group. Notifications linkUbiquitous Language link Concept Description Synonyms Push notification A real-time message sent to a user’s device to inform about a relevant event. Notification message The actual content of the push notification that is displayed to the user. Registration token A unique token associated with a user’s device for sending push notifications. Token, Device Token Commands link Command Description Group Wise Push Notification A push notification to be sent to all the members of a group. Co Members Push Notification A push notification to be sent to all users sharing at least one group with a specific user. Chat linkUbiquitous Language link Concept Description Synonyms Client An individual that connect to a chat group User, Group Member Group A set of Clients that chat between each other Chat Room Message A text message that is sent from a client in a group. Events link 🏷️ Event Type Event Name Description 🚀 Driving event SampledLocation The event sent from the client application to update the user’s location. RoutingStarted The event sent from the client application to start the user’s route tracking towards a destination. RoutingStopped The event sent from the client application to stop the user’s route tracking. SOSAlertTriggered The event sent from the client application to trigger an SOS alert, carrying the user’s location. SOSAlertStopped The event sent from the client application to stop the SOS alert. 📥 Driven event UserUpdate The event sent from the Location Service to notify the client application about the user’s state or location update. Bounded Context Integration linkThe boundary of each bounded context delineates the scope of the context: models in different bounded context can be evolved and implemented independently, but they need to be integrated to provide a coherent service to the users.\nDDD provides a set of patterns for defining relationship and integrations between bounded contexts to be reified in the so-called Context Map, a visual representation of the system’s bounded contexts and the relationships between them.\nThe following diagram shows the context map of the PositionPal system:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e "
            }
        );
    index.add(
            {
                id:  8 ,
                href: "\/docs\/3-arch-design\/2-architecture-design\/",
                title: "Architecture Design",
                description: "Following the identification and definition of the quality attributes, a microservice architecture was chosen. This is characterized by the decomposition of the system into a set of independent, and loosely coupled services, each of which is responsible for a specific business domain or functionality. Indeed, the use of this architectural style enables the continuous delivery and deployment of large, complex applications, the ability to scale horizontally with ease, the possibility to use different technologies and programming languages for each service and an increase in the overall system’s maintainability. Moreover it allows to isolate failures and to improve the fault tolerance of the system, hence gaining in reliability.\n",
                content: "Following the identification and definition of the quality attributes, a microservice architecture was chosen. This is characterized by the decomposition of the system into a set of independent, and loosely coupled services, each of which is responsible for a specific business domain or functionality. Indeed, the use of this architectural style enables the continuous delivery and deployment of large, complex applications, the ability to scale horizontally with ease, the possibility to use different technologies and programming languages for each service and an increase in the overall system’s maintainability. Moreover it allows to isolate failures and to improve the fault tolerance of the system, hence gaining in reliability.\nMicroservices Decomposition linkFollowing the decompose by subdomain strategy the following microservices have been identified:\nUser Service: responsible for managing the user account data and the groups of the system; Location Service: responsible for managing the location and the user tracking; Notification Service: responsible for managing the notifications; Chat Service: responsible for managing the chat messages. Both the Groups and User bounded contexts have been consolidated within the user service due to their strong interrelation and need for frequent, seamless interaction. Separating them into distinct microservices would compromise data consistency and introduce unacceptable levels of latency, making this integration a more efficient and reliable solution. Indeed, while it’s common to map a bounded context to a single microservice, this isn’t always the case 1.\nMoreover, to aggregate the functionalities of the different microservices, we have chosen to use the API Gateway pattern. This pattern is used to aggregate the functionalities of the architecture, providing a single entry point for the client applications. The API Gateway is responsible for routing the requests to the appropriate service, aggregating the responses, and providing a unified interface to the client applications.\nArchitecture Documentation linkHigh-Level Overview linkTo address the challenges of scalability, decoupling, and real-time processing, the system’s architecture was designed following an event-driven microservice approach, in which the microservices are mainly designed to interact by means of event streams.\nThis paradigm enables asynchronous communication between the services, allowing them to be loosely coupled and independent from each other, hence making the system more resilient and maintainable.\nFor this purpose, the architecture is designed around a Message/Event Broker, which acts as a central communication hub for the microservices, enabling them to publish and subscribe to events, and exchange messages in a reliable and scalable way.\nNonetheless, regarding the communications between the client and the microservices through the API Gateway, an RPC protocol is used, in order to ensure synchronous communication. This approach enables the client to invoke remote procedures on the microservices and receive a response in a synchronous manner (e.g. for the authentication process).\nLastly, each microservice follow the best practice of having its own database, ensuring data isolation and independence from other services, allowing a loosely coupled architecture whose communications happen only through the message broker via a standard protocol. This has also the advantage of letting the developers change a service’s schema without affecting, and thus coordinating, with other services teams.\nFollowing these high-level principles, in the following sections we provide a detailed view of the system’s architecture, though the three main structural views: Components and Connectors, Modules and Allocation.\nC\u0026C View linkThe following diagrams shows the Component and Connector (C\u0026C) view of the system, providing a high-level picture of the system’s runtime entities in action and their boundaries.\nIn order to avoid overwhelming the reader with an all-encompassing but rather confusing scheme, we provide below a C\u0026C view of the system by providing, for each microservice, its relative UML diagram.\nUser and Group Service link Location Service linkThe Location Service interacts with the Gateway, exposing two different API ports: one for real-time tracking via a real-time connector, allowing users to be tracked, and another for accessing tracking service information through an RPC connector. Like, any other microservice, it has its own database for storing the tracking data, and it interacts with the message broker to publish notifications and subscribe to group events.\nChat Service linkSimilarly to the location service, the chat service exposes two different API ports: one for real-time chat communication via a real-time connector, and another for accessing chat service information through an RPC connector. It stores the chat data in its own database and interacts with the message broker for receiving group events.\nNotification service linkThe notification service expose a input port through which an RPC connector is possible to subscribe to notifications by clients. It has a data access port to interact with the database and two output ports to receive group updates and notification commands.\nDeployment View linkTODO\nHexagonal Architecture linkIn compliance with DDD principles, the microservices are designed following the Hexagonal Architecture pattern (also known as Ports and Adapters or Onion Architecture), which is a particular instantiation of the layered architecture, that is well-suited for microservices to preserve models’ integrity. Indeed, the primary advantage of this pattern is the separation of concerns, which allows the business logic to be decoupled from the infrastructure and the external systems (e.g., databases, message brokers, etc.) hence making the system more maintainable and testable, and the business logic more reusable.\nEach layer of the Hexagonal Architecture has been enforced in the code by mapping them into modules (like Grade submodules) each of which with its own build dependencies and responsibilities, as shown in the following diagram:\nHow to define subdomains ↩︎\n"
            }
        );
    index.add(
            {
                id:  9 ,
                href: "\/docs\/3-arch-design\/4-patterns\/",
                title: "Architectural Patterns",
                description: "In this page are collected the Microservice Architectural Pattern we used in the design of the system, following the Chris Richardson’s taxonomy\nService collaboration linkDatabase per Service linkEach microservice’s persistent data is private to that service and accessible only via its API. More specifically, an approach where each microservice has its own schema has been adopted, favoring data isolation, making ownership of the data clearer and ensuring the services are loosely coupled.\n",
                content: "In this page are collected the Microservice Architectural Pattern we used in the design of the system, following the Chris Richardson’s taxonomy\nService collaboration linkDatabase per Service linkEach microservice’s persistent data is private to that service and accessible only via its API. More specifically, an approach where each microservice has its own schema has been adopted, favoring data isolation, making ownership of the data clearer and ensuring the services are loosely coupled.\nDomain event linkSince the notification, location, and chat microservices all require information about group members to function correctly, a query-based approach would be inefficient and would degrade system performance, especially given the need to handle high volumes of data and requests. To address this, the architecture is designed to be event-driven. The user service publishes domain events whenever a group-related action occurs, such as adding or removing a member.\nThis approach ensures that all the services that need to know this information can subscribe to the events and update their local projections accordingly. As in the observer pattern, the publisher does not know who is interested in the event and, therefore, does not need to be aware of the subscribers that may change in the future (for example because of the addition of a new service) with no impact on the publisher.\nOn the downside, this approach makes the system eventually consistent, but this is a trade-off that has been accepted in order to ensure the system’s scalability and performance.\nEvent sourcing linkFor the location and chat services, the Event Sourcing pattern is adopted. This patterns consists of persisting the state of a business entity such as a sequence of state-changing events. Whenever the state of the business entity changes a new event is appended to the list of events, making it possible for the application to reconstruct the entity’s state by replaying the events.\nThis approach suits well both the location and chat services, as they need to keep track of the history of the location updates and chat messages, respectively. Moreover, this approach allows the system to be more resilient to failures, as the state can be reconstructed by replaying the events, and more scalable as it enables efficient distribution of workload across multiple services, reduces contention on the database by leveraging an append-only storage model, and facilitates the creation of optimized read models through event-driven processing.\nCQRS linkSince different services, other than the Users \u0026 Groups service requires the groups information to properly function, the Command Query Responsibility Segregation pattern is adopted.\nEvery microservice that has the need to know the group members information have their own read-only ‘replica’ that is designed specifically to serve the queries of that service. The service keeps the database up to date by subscribing to Domain events published by the service that own the data, in our case the Users \u0026 Groups service. This pattern allows each service to support its own denormalized view of the groups data that is optimized for its specific needs, ensuring that the services are loosely coupled and that the system is scalable and performant. No complex and slow queries are needed to be executed on the user service to retrieve the group members information, as the data is already available in the read-only replica of the service that needs it. This also improves the overall system responsiveness.\nCommunication styles linkIn accordance to the Domain event pattern the interactions between the microservices are asynchronous: they exchange messages over messaging channels through a Message/Event Broker.\nThough, the communication between the client and the microservices through the API Gateway is synchronous though an RPC protocol, allowing the client to invoke remote procedures on the microservices and receive a response in a synchronous manner (e.g. for the authentication process), adhering to the Request/Reply pattern.\nExternal API linkAPI Gateway linkThe API Gateway is the single entry point for all clients, providing a unified interface to the system’s microservices. It’s main purpose is to aggregate the functionalities of the architecture, routing the requests to the appropriate service, aggregating the responses, and providing a unified interface to the client applications. Moreover, it is responsible for ensuring the security of the system, handling authentication and authorization. Lastly, it surely provides communication protocols translation (e.g. from REST to gRPC or Websocket to a Message Broker).\nSecurity linkAccess Token linkThe system uses the Access Token pattern to ensure the security of the system. The Access Token pattern is used to provide a secure way to access the system’s resources, ensuring that only authorized users can access the system’s functionalities. For each request, the client must provide a valid access token, which is then validated by the system to ensure that the user is authorized to access the requested resource.\nDeployment Patterns linkService-per-Container linkEach service is packages as a container image and deployed as a separate and independent container. This pattern allows each service to be deployed and scaled independently, ensuring that the system is resilient and scalable.\nService deployment platform linkTODO\n"
            }
        );
    index.add(
            {
                id:  10 ,
                href: "\/docs\/4-detailed-design\/",
                title: "Detailed Design",
                description: "The detailed design of the system.",
                content: ""
            }
        );
    index.add(
            {
                id:  11 ,
                href: "\/docs\/4-detailed-design\/0-overall-architecture\/",
                title: "Big Picture",
                description: "The following schema provides a high-level overview of the system, illustrating its components and their main interactions. The goal is to give the reader a clear understanding of the system’s structure and dynamics without formal specifications.\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e ",
                content: "The following schema provides a high-level overview of the system, illustrating its components and their main interactions. The goal is to give the reader a clear understanding of the system’s structure and dynamics without formal specifications.\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e "
            }
        );
    index.add(
            {
                id:  12 ,
                href: "\/docs\/4-detailed-design\/1-shared-kernel\/",
                title: "Shared Kernel design",
                description: "The shared kernel includes the common entities used by all services. Its primary objective is to encapsulate only the integration contracts and data structures meant to be passed across the boundaries of the bounded contexts.\nSince the system’s architecture is event-driven, communication between microservices occurs exclusively through events and commands exchanged via the message broker. These events and commands have been represented as classes and interfaces, as illustrated in the following UML diagram. This approach facilitates and reduce the cost of duplicating code across services, ensuring consistency and coherence in the system’s communication.\n",
                content: "The shared kernel includes the common entities used by all services. Its primary objective is to encapsulate only the integration contracts and data structures meant to be passed across the boundaries of the bounded contexts.\nSince the system’s architecture is event-driven, communication between microservices occurs exclusively through events and commands exchanged via the message broker. These events and commands have been represented as classes and interfaces, as illustrated in the following UML diagram. This approach facilitates and reduce the cost of duplicating code across services, ensuring consistency and coherence in the system’s communication.\nThe events package contains all the events that can be triggered by the system, including group creation and removal, as well as the addition or removal of members from a group. The commands package contains all the commands that can be sent to the system. It includes the PushNotificationCommand, an abstract class representing a push notification command. This class has two concrete implementations: GroupWisePushNotification - a command that sends a push notification to all members of a specific group. CoMembersPushNotification - a command that sends a push notification to all users sharing a group with a specific user. Both commands and events rely on shared value objects and entities that represent the core concepts of the system, such as UserId, GroupId, User, and NotificationMessage. It is important to note that these entities contain only the attributes required to fulfill integration needs. More complex design details are delegated to individual services, which are responsible for managing their own data and requirements and are free to evolve independently of other services. "
            }
        );
    index.add(
            {
                id:  13 ,
                href: "\/docs\/4-detailed-design\/5-user-groups-service\/",
                title: "User and Group Service design",
                description: "In this section it is presented the abstract design of the User and Group Service. As per best practices, the design is based on the Domain-Driven Design principles, and is presented in terms of the main three views: structure, interaction, and behavior.\nAbstract Design linkStructure linkThe main domain concepts and events are presented hereafter and reified in the following classes structure, following the DDD building blocks.\nUser: The User entity represents an individual in the system. Each User is uniquely identified by a value object, UserId, ensuring consistency and traceability. The entity includes attributes such as name, email, and password, which can be updated while maintaining the same identity.\n",
                content: "In this section it is presented the abstract design of the User and Group Service. As per best practices, the design is based on the Domain-Driven Design principles, and is presented in terms of the main three views: structure, interaction, and behavior.\nAbstract Design linkStructure linkThe main domain concepts and events are presented hereafter and reified in the following classes structure, following the DDD building blocks.\nUser: The User entity represents an individual in the system. Each User is uniquely identified by a value object, UserId, ensuring consistency and traceability. The entity includes attributes such as name, email, and password, which can be updated while maintaining the same identity.\nGroup The Group entity represents a collection of users. It is identified by a GroupId value object and has attributes like a group name and a list of members (Users). The association (Group → 0..* User) signifies that a group can have zero or more users, enabling flexible management of group memberships.\nMembership The Membership value object captures the relationship between a user and a group. It includes the UserId and GroupId value objects, establishing a many-to-many association between users and groups. This structure allows for efficient querying of group memberships and user-group relationships.\nSecret, Issuer, Audience These value objects are part of the authentication domain and represent the secret key, issuer, and audience of the JWT token, respectively. They encapsulate the necessary information for token generation and validation, ensuring secure authentication and authorization processes.\nRepositories:\nUserRepository: Abstracts the persistence operations for User entities by exposing methods such as save(user: User), findById(id: UserId): User, and delete(user: User).\nGroupRepository: Similarly abstracts persistence for Group entities with equivalent operations.\nAuthRepository: Provides methods for checking user credentials during authentication.\nServices:\nUserService: Contains business logic for creating, updating, and deleting users. It leverages the UserRepository for data operations and publishes a UserCreated event when a new user is created.\nGroupService: Manages group-related operations such as creating groups, adding users to groups, and removing users from groups. It uses the GroupRepository for data access and publishes GroupCreated, UserAddedToGroup, and UserRemovedFromGroup events as necessary.\nAuthService: Handles user authentication and authorization. It verifies user credentials against the AuthRepository and generates JWT tokens for authenticated users.\nInteraction linkThe interaction between the main components of the system is described in the following sequence diagram.\nUser Registration: A new user registers by sending their username, email, and password to the Auth Service. The service persists the new user in the User-Group Store, publishes a UserCreated event on the Event Bus, and returns the created user details.\nUser Login: The user logs in by providing credentials. The Auth Service validates these against the User-Group Store and returns a UserSession (including a token).\nUser Modification: The user modifies their own details (e.g., changing name, surname or password) by sending an update request to the Auth Service. The service updates the record, publishes a UserUpdated event, and returns the updated user information.\nGroup Creation: The user creates a group through the Group Handler. The handler persists the new group (recording the creator’s UserID), publishes a GroupCreated event, and returns the group details.\nGroup Update: The user updates the group’s name via the Group Handler. The updated details are persisted, a GroupUpdated event is published, and the updated group details are returned.\nUser Join Group: The user joins a group by sending a join request to the Group Handler. The Group Handler adds the user to the group in the store, publishes a UserAddedToGroup event, and returns the updated group details.\nRemove Member from Group: The user (or possibly a group owner) removes a target member from the group by sending a removal request. The Group Handler updates the membership in the store, publishes a UserRemovedFromGroup event, and returns the updated group details.\nUser Logout: The user logs out by sending a logout request to the Auth Service. The service invalidates the session in the store and returns a logout acknowledgment.\nPlease, note the diagram illustrates only the main success flow, leaving out the error handling and the edge cases.\n"
            }
        );
    index.add(
            {
                id:  14 ,
                href: "\/docs\/4-detailed-design\/2-location-service\/",
                title: "Location Service design",
                description: " In this section it is presented the abstract design of the Location Service. As per best practices, the design is based on the Domain-Driven Design principles, and is presented in terms of the main three views: structure, interaction, and behavior.\nAbstract Design linkStructure linkThe main domain concepts and events are presented hereafter and reified in the following classes structure, following the DDD building blocks.\n",
                content: " In this section it is presented the abstract design of the Location Service. As per best practices, the design is based on the Domain-Driven Design principles, and is presented in terms of the main three views: structure, interaction, and behavior.\nAbstract Design linkStructure linkThe main domain concepts and events are presented hereafter and reified in the following classes structure, following the DDD building blocks.\nScope: A value object representing the context in which an event occurs. It is composed of a user and a group, capturing the idea that a user’s state can differ from group to group, enabling group-specific visibility and tracking. Tracking: An entity representing the user’s route information at a certain point in time, it is composed of a list of positions that can be interpolated to form a path between two geographical positions. MonitorableTracking: a specialized Tracking entity that includes the mode of transportation, the destination, the expected arrival time, enabling the system to monitor the user’s route and trigger alerts when necessary. Session: An aggregate root entity storing the overall state of a user in a group at a certain point in time. It acts as a state machine, updating the state and the tracking information based on the received events, ensuring the consistency of the user’s state is maintained. A Snapshot is a value object capturing a snapshot of the user’s state. DomainEvent: An interface representing the base structure of a domain event, capturing the timestamp, the user, and the group in which the event occurs. It is the base type for all the events that occur in the system. DrivingEvent: An interface representing the base structure of a driving event, i.e. a valuable event guiding an application use case. ClientDrivingEvent: A specialized DrivingEvent interface representing the events that are triggered by the user’s actions, such as sampling the location, triggering an SOS alert, starting or stopping a routing. InternalDrivingEvent: A specialized DrivingEvent interface representing the events that are triggered by the system, such as the user going offline, triggering a stuck alert, or a timeout alert. DrivenEvent: An interface representing the base structure of a driven event, i.e. an event triggered by the system as a result of some system state change / action. The application services and repositories are presented in the following diagram, which presents only the main interfaces, leaving out the implementation and the adapters classes.\nMapsService: the service responsible for calculating the distance and the duration between two geographical positions, based on the mode of transportation. NotificationService: the service responsible for sending notifications, acting as a proxy towards the notification service. The concrete adapter is in charge of sending the notification to the appropriate channel of the message broker. RealTimeTracking: the service responsible for handling the driving events, acting as an input port for the external adapters. It allows to register observers to be get back real-time updates. Clients can in any moment get a snapshot of the user’s state and location by querying the UsersSessionService service, which is responsible for managing the user’s session state. The actual tracking information are stored through the UserSessionStore repository, which is responsible for the persistence of the user’s session state. A UserSessionStore is both a Writer and a Reader for the Session entity. Separate write-side and read-side interfaces are defined to ensure the separation of concerns and the single responsibility principle, leaving the implementation open to adhere to CQRS pattern. UserGroupsService is responsible for managing the saving and retrieval of the groups members through the UserGroupsStore repository. Updates happen thanks the events propagated by the User service via the message broker. Interaction linkThe interaction concerning the real-time user tracking between the main components of the system is described in the following sequence diagram.\nThe Group Member connects to the RealTimeTracking service through a Real Time Communication Connector starting observing the updates of the group members it belongs to. However, before starting reacting to these updates, it fetches the current state of all group members through the UsersSessionService service, ensuring a consistent view of their state. Once the current state of all members is obtained, it starts reacting to the updates of other groups members while sending its own updates to the service. The RealTimeTracking service, upon receiving the updates, reacts to the events and updates the user’s session state, sending back the result to all the group members currently observing group’s changes.\nPlease, note the diagram illustrates only the main success flow, leaving out the error handling and the edge cases. Moreover, the interaction between the Group Member and the tracking services is mediated by the gateway, which is not shown in the diagram.\nBehavior linkAs an event driven architecture, the state of each group’s member can be described by the following state diagram, drawing the possible state transitions that can be fired by one of the above DrivingEvent.\n"
            }
        );
    index.add(
            {
                id:  15 ,
                href: "\/docs\/4-detailed-design\/4-chat-service\/",
                title: "Chat Service design",
                description: "Chat service is responsible for managing the communication between users in real-time. This document describes the detailed design of the chat service, including its architecture, components, and interactions.\nAbstract Design linkHere are presented the main components of the chat service, we start describing the foundamental entities of the domain, then we move to the infrastructure layer, where we define the commands and events that will be used to interact with the domain entities.\n",
                content: "Chat service is responsible for managing the communication between users in real-time. This document describes the detailed design of the chat service, including its architecture, components, and interactions.\nAbstract Design linkHere are presented the main components of the chat service, we start describing the foundamental entities of the domain, then we move to the infrastructure layer, where we define the commands and events that will be used to interact with the domain entities.\nStructure link Client: An entity that represents a user connected to the chat service. It has an identifier, a status, and a reference to the output channel. ClientID: A value object that represents the unique identifier of a client that connects to the chat service. This is a 1-1 mapping to the user identifier used in the shared kernel.\nOutputReference: A value object that represents the reference to the output channel of a client. This reference is used to send messages to the client.\nGroup: An entity that represents a group of clients that can communicate with each other. It has an identifier and a list of clients. GroupID: A value object that represents the identifier of a group. This is a 1-1 mapping to the group identifier used in the shared kernel. ClientMessage: An entity that represents a message sent by a client to a group. It contains the sender, the group, the content, and the timestamp of the message. In the following diagram are presented the main services interfaces that will be used to interact with the domain entities and to respond to the external events.\nInteraction between Entities linkFinally, we present the interaction between the main components of the chat service. The following diagram shows the sequence of main events that occours inside the chat service.\n"
            }
        );
    index.add(
            {
                id:  16 ,
                href: "\/docs\/4-detailed-design\/3-notification-service\/",
                title: "Notification Service design",
                description: "In this section is presented the abstract design of the notification service.\nAs already presented, its main responsibility is to send notifications to the users, based on the events that occur in the system.\nStructure linkThe structure of the service is quite simple:\nToken is a value object that represents the token used to identify the device of a user. UserToken is an entity that represents the association between a user and a token. UsersTokensService is the service that allows registering and invalidating tokens for users. UsersTokensRepository is the repository that stores the associations between users and tokens. NotificationPublisher is the service that sends notifications to users. PublishingTargetStrategy is the strategy used to determine the target of the notification. Two stategies exists: one to send to all members of a group (corresponding to the GroupWisePushNotification command) and another to send to all members sharing a group with a user (corresponding to the CoMembersPushNotification command). GroupsRepository is the repository that allows storing and retrieving the members of the groups. This is called by the message broker adapter on every events whose topic is related to groups state changes. Interaction linkThe main flow scenario is describe below and depicted in the following sequence UML diagram.\n",
                content: "In this section is presented the abstract design of the notification service.\nAs already presented, its main responsibility is to send notifications to the users, based on the events that occur in the system.\nStructure linkThe structure of the service is quite simple:\nToken is a value object that represents the token used to identify the device of a user. UserToken is an entity that represents the association between a user and a token. UsersTokensService is the service that allows registering and invalidating tokens for users. UsersTokensRepository is the repository that stores the associations between users and tokens. NotificationPublisher is the service that sends notifications to users. PublishingTargetStrategy is the strategy used to determine the target of the notification. Two stategies exists: one to send to all members of a group (corresponding to the GroupWisePushNotification command) and another to send to all members sharing a group with a user (corresponding to the CoMembersPushNotification command). GroupsRepository is the repository that allows storing and retrieving the members of the groups. This is called by the message broker adapter on every events whose topic is related to groups state changes. Interaction linkThe main flow scenario is describe below and depicted in the following sequence UML diagram.\nEach group member registers its device token to the notification service through an external infrastructural component that will handle the reliable delivery of the notification to the device. Here it is abstracted away as PushNotificationInfrastructure. This token is stored in the UsersTokensRepository and associated with the user id. When a notification command is received, the NotificationPublisher retrieves the members of the group and sends the notification to each member’s device.\n"
            }
        );
    index.add(
            {
                id:  17 ,
                href: "\/docs\/5-implementation\/",
                title: "Implementation Details",
                description: "The internals of the system",
                content: ""
            }
        );
    index.add(
            {
                id:  18 ,
                href: "\/docs\/5-implementation\/0-common\/",
                title: "Implementation details for common services",
                description: "Message Broker and RPC technologies linkWhy RabbitMQ? Why gRPC?\n** tecnologie tipologia ** TODO - GIOVA\nGateway linkThe gateway is the entry point of the system and is the only service that is exposed to the outside world. Their main responsibilities and features are:\nrouting each request to the correct service after having authenticated and authorized the user: it is important that only authenticated users can access the services and that they can only access the functionalities they are allowed to use. For example, a user can only access the functionalities of the group they belong to. protocol translation: for synchronous remote procedure calls it is a best practice to use a ReST based API over the chosen gRPC protocol. This is because ReST APIs can be easily consumed by any client since they leverage standard HTTP methods and formats (like JSON), while gRPC APIs are more efficient but require specialized client libraries to handle Protobuf messages and HTTP/2 connections. since it is the entry-point of the system it can be a single point of failure and a bottleneck. To avoid this it is implemented like a stateless service, so it can be easily scaled horizontally to handle more requests and to be fault-tolerant. flowchart RL client[Client Applications] --\u003e|HTTP/REST| gateway[API Gateway] subgraph gateway_components[API Gateway Components] auth[Authentication] authoriz[Authorization] router[Request Router] translator[Protocol Translator] response_translator[Response Translator] end gateway --\u003e auth auth --\u003e authoriz authoriz --\u003e router router --\u003e translator translator --\u003e|gRPC| serviceA[Location Service \\n REST API] translator --\u003e|wss| serviceB[Location Service \\n Websocket API] translator --\u003e|gRPC| serviceC[User Service \\n gRPC API] translator --\u003e|gRPC| serviceD[Chat Service \\n gRPC API] translator --\u003e|wss| serviceE[Chat Service \\n Websocket API] translator --\u003e|gRPC| serviceF[Notification Service \\n gRPC API] serviceA .-\u003e response_translator serviceB .-\u003e response_translator serviceC .-\u003e response_translator serviceD .-\u003e response_translator serviceE .-\u003e response_translator serviceF .-\u003e response_translator response_translator --\u003e|HTTP/REST| gateway gateway --\u003e|HTTP/REST| client classDef gateway fill:#f96,stroke:#333,stroke-width:2px classDef client fill:#9d9,stroke:#333,stroke-width:1px classDef component fill:#fcf,stroke:#333,stroke-width:1px class gateway gateway class client client class auth,router,translator,authoriz,response_translator component The API Gateway is implemented using Express, a lightweight and flexible Node.js framework that simplifies the creation of web applications and APIs.\n",
                content: "Message Broker and RPC technologies linkWhy RabbitMQ? Why gRPC?\n** tecnologie tipologia ** TODO - GIOVA\nGateway linkThe gateway is the entry point of the system and is the only service that is exposed to the outside world. Their main responsibilities and features are:\nrouting each request to the correct service after having authenticated and authorized the user: it is important that only authenticated users can access the services and that they can only access the functionalities they are allowed to use. For example, a user can only access the functionalities of the group they belong to. protocol translation: for synchronous remote procedure calls it is a best practice to use a ReST based API over the chosen gRPC protocol. This is because ReST APIs can be easily consumed by any client since they leverage standard HTTP methods and formats (like JSON), while gRPC APIs are more efficient but require specialized client libraries to handle Protobuf messages and HTTP/2 connections. since it is the entry-point of the system it can be a single point of failure and a bottleneck. To avoid this it is implemented like a stateless service, so it can be easily scaled horizontally to handle more requests and to be fault-tolerant. flowchart RL client[Client Applications] --\u003e|HTTP/REST| gateway[API Gateway] subgraph gateway_components[API Gateway Components] auth[Authentication] authoriz[Authorization] router[Request Router] translator[Protocol Translator] response_translator[Response Translator] end gateway --\u003e auth auth --\u003e authoriz authoriz --\u003e router router --\u003e translator translator --\u003e|gRPC| serviceA[Location Service \\n REST API] translator --\u003e|wss| serviceB[Location Service \\n Websocket API] translator --\u003e|gRPC| serviceC[User Service \\n gRPC API] translator --\u003e|gRPC| serviceD[Chat Service \\n gRPC API] translator --\u003e|wss| serviceE[Chat Service \\n Websocket API] translator --\u003e|gRPC| serviceF[Notification Service \\n gRPC API] serviceA .-\u003e response_translator serviceB .-\u003e response_translator serviceC .-\u003e response_translator serviceD .-\u003e response_translator serviceE .-\u003e response_translator serviceF .-\u003e response_translator response_translator --\u003e|HTTP/REST| gateway gateway --\u003e|HTTP/REST| client classDef gateway fill:#f96,stroke:#333,stroke-width:2px classDef client fill:#9d9,stroke:#333,stroke-width:1px classDef component fill:#fcf,stroke:#333,stroke-width:1px class gateway gateway class client client class auth,router,translator,authoriz,response_translator component The API Gateway is implemented using Express, a lightweight and flexible Node.js framework that simplifies the creation of web applications and APIs.\nIn this scenario, middleware plays a crucial role in the request-response lifecycle. Middleware functions in Express are used to process incoming requests before they reach the core business logic and to handle responses before they are sent back to the client. This modular approach helps organize the application logic into smaller, reusable components that can be stacked and composed as needed.\n…\nShared Kernel link** tecnologie codice ** TODO - VALE\n"
            }
        );
    index.add(
            {
                id:  19 ,
                href: "\/docs\/5-implementation\/4-user-groupd-service\/",
                title: "User and Group Service implementation details",
                description: "This chapter provides an overview of the implementation details of the User and Group Service.\nHigh level overview and modules structure linkThe User and Group Service is responsible for managing the users and groups of the system. It is a core service that is used by other services to manage the users and groups of the system.\nThe User and Group Service is composed of the following modules:\nUser Management Module: This module is responsible for managing the users of the system. It provides APIs for creating, updating, deleting, and retrieving user information.\n",
                content: "This chapter provides an overview of the implementation details of the User and Group Service.\nHigh level overview and modules structure linkThe User and Group Service is responsible for managing the users and groups of the system. It is a core service that is used by other services to manage the users and groups of the system.\nThe User and Group Service is composed of the following modules:\nUser Management Module: This module is responsible for managing the users of the system. It provides APIs for creating, updating, deleting, and retrieving user information.\nGroup Management Module: This module is responsible for managing the groups of the system. It provides APIs for creating, updating, deleting, and retrieving group information.\nMembership Management Module: This module is responsible for managing the relationship between users and groups. It provides APIs for adding users to groups, removing users from groups, and retrieving the users of a group.\nUser Service linkUser Authentication and Identity Management linkThe core responsibility of the User Service is handling user authentication and identity management, which forms the foundation of the entire PositionPal platform. This service must maintain robust and secure user profiles, manage user authentication flows, and provide user data to other services in a consistent and reliable manner.\nThe critical challenge is balancing security with performance while maintaining a clear separation of concerns in a microservice architecture. User data must be protected, yet accessible to authorized services across the platform.\nClean Architecture Implementation linkFor the User Service implementation, we adopted a Clean Architecture approach with clearly separated layers. This architectural choice provides significant benefits for a service responsible for sensitive user data:\nuser-service/ ├── domain/ # Core business entities and rules ├── application/ # Use cases and service interfaces ├── storage/ # Database and persistence implementations ├── presentation/ # Protocol definitions ├── grpc/ # gRPC service implementations ├── rabbitmq/ # Message integration └── entrypoint/ # Application bootstrap Each layer has a specific responsibility and communicates only with adjacent layers, with dependencies pointing inward toward the domain layer. This approach allows us to isolate the core business logic from implementation details.\nThe domain layer contains pure business entities and rules, uncontaminated by external frameworks or technologies. For example, the User entity contains only the essential properties and validation rules:\ndata class User( val userData: UserData, val password: String, ) data class UserData( val id: String, val name: String, val surname: String, val email: String, ) The application layer defines service interfaces and use cases without implementation details. For instance, the UserService interface specifies what the service can do without dictating how:\ninterface UserService { suspend fun createUser(user: User): User suspend fun getUser(id: UserID): User? suspend fun updateUser(id: UserID, firstName: String, lastName: String): User? suspend fun deleteUser(id: UserID): Boolean suspend fun getUserByEmail(email: Email): User? } This clean separation facilitates testing and allows different implementations without affecting the core domain logic.\nGroup Service linkAn interesting aspect of the User Service implementation is the management of user groups. We applied Domain-Driven Design principles to model this complex relationship:\ndata class Group( val id: String, val name: String, val members: List, val createdBy: UserData, ) The Membership entity encapsulates all the business rules regarding group membership.\ndata class Membership( val userId: String, val groupId: String, ) Group Operations and Membership Management linkHere’s the interface that defines what our Group Service can do:\ninterface GroupService { fun createGroup(group: Group): Group fun getGroup(groupId: String): Group? fun updateGroup(groupId: String, group: Group): Group? fun deleteGroup(groupId: String): Boolean fun addMember(groupId: String, userData: UserData): Group? fun removeMember(groupId: String, userData: UserData): Group? fun findAllGroupsOfUser(email: String): List fun findAllGroupsByUserId(id: String): List } Authentication Implementation with JWT linkThe User Service implements JWT-based authentication, which is crucial for a microservice architecture where multiple services need to verify user identity without direct database access.\nThe service uses a combination of password hashing (with BCrypt) for secure storage and JWT tokens for stateless authentication:\ninterface AuthService { fun authenticate(email: String, password: String): String? fun authorize(token: String): Boolean fun getEmailFromToken(token: String): String? } class AuthServiceImpl( private val authRepository: AuthRepository, private val secret: Secret, private val issuer: Issuer, private val audience: Audience, private val expirationTime: Int = EXPIRATION_TIME, ) : AuthService { override fun authenticate(email: String, password: String): String? { ... return JWT.create() .withIssuer(issuer.value) .withAudience(audience.value) .withClaim(\"email\", email) .withExpiresAt(Date(System.currentTimeMillis() + expirationTime)) .sign(algorithm) } } This implementation follows the Strategy Pattern where different authentication methods could be plugged in, though currently JWT is the primary method. The service is designed to easily support additional authentication strategies if needed.\nprivate val algorithm = Algorithm.HMAC256(secret.value) Inter-Service Communication with gRPC linkA significant challenge in implementing the User Service was defining how other services would interact with user data. We chose gRPC for synchronous service-to-service communication for several reasons:\nType safety: Protocol buffers provide strict contract definitions; Performance: gRPC offers better performance than REST/JSON; Automatic code generation: Simplifies development by reducing repetitive code and maintaining consistency across services. The service interfaces are defined using Protocol Buffers:\nservice UserService { rpc CreateUser (CreateUserRequest) returns (CreateUserResponse); rpc GetUser (GetUserRequest) returns (GetUserResponse); rpc UpdateUser (UpdateUserRequest) returns (UpdateUserResponse); rpc DeleteUser (DeleteUserRequest) returns (DeleteUserResponse); rpc GetUserByEmail (GetUserByEmailRequest) returns (GetUserByEmailResponse); } service AuthService { rpc Login (LoginRequest) returns (LoginResponse); rpc ValidateToken (ValidateTokenRequest) returns (ValidateTokenResponse); } The gRPC service adapters then translate between these protocol messages and domain objects, following the Adapter Pattern:\nclass GrpcUserServiceAdapter(private val userService: UserService) : UserServiceCoroutineImplBase() { override suspend fun createUser(request: CreateUserRequest): CreateUserResponse { try { val createdUser = userService.createUser(mapFromGrpcUser(request.user)) return CreateUserResponse.newBuilder() .setUser(mapToGrpcUser(createdUser).userData) .setStatus(createStatus(StatusCode.OK, \"User created successfully\")) .build() } catch (e: Exception) { return CreateUserResponse.newBuilder() .setStatus(createStatus(StatusCode.INTERNAL_ERROR, e.message)) .build() } } // Additional methods... } This adapter implementation allows us to keep the service interface stable while the internal implementation can evolve independently. The mapping functions handle the translation between domain models and protocol buffer messages, ensuring a clean separation of concerns.\nEvent-Driven Communication with RabbitMQ linkFor asynchronous communication scenarios, such as notifying other services when users are created or updated, we implemented an event-driven approach using RabbitMQ with the Observer Pattern.\nThe User Service publishes domain events when user-related actions occur, such as member join group or group creation. Other services can subscribe to these events and update their local projections accordingly.\nThe message adapter uses the Strategy Pattern for serialization, allowing different serialization methods (currently Avro) to be used.\nGroup Event Publication System linkOne of the most interesting aspects of our implementation is how we’ve embraced event-driven architecture—but specifically focused on group operations.\nIn our system, we publish events exclusively for group-related operations through RabbitMQ. Here’s what that looks like:\nenum class EventType { GROUP_CREATED, GROUP_UPDATED, GROUP_DELETED, MEMBER_ADDED, MEMBER_REMOVED } Each event type corresponds to a significant domain event within our Group Service. When a group is created, members are added or removed, or a group is deleted, we publish an event to notify other services that might need to react to these changes.\nData Persistence with Repository Pattern linkThe User Service uses the Repository Pattern to abstract database operations, making it possible to change the underlying database without affecting the business logic:\ninterface UserRepository { fun save(user: User): User fun findById(userId: String): User? fun update(user: User): User? fun deleteById(userId: String): Boolean fun findAll(): List fun findByEmail(email: String): User? } We use Ktorm, a lightweight ORM, to interact with PostgreSQL:\nobject Users : BaseTable(\"users\") { val id = varchar(\"id\").primaryKey() val name = varchar(\"name\") val surname = varchar(\"surname\") val email = varchar(\"email\") val password = varchar(\"password\") override fun doCreateEntity(row: QueryRowSet, withReferences: Boolean) = User( userData = UserData( id = row[id].orEmpty(), name = row[name].orEmpty(), surname = row[surname].orEmpty(), email = row[email].orEmpty(), ), password = row[password].orEmpty(), ) } Testing Strategy linkThe User Service includes comprehensive testing at multiple levels:\nUnit testing: Focused on domain logic and service implementations Integration testing: Testing repositories with actual database connections For integration tests, we use Docker Compose to spin up dependent services:\ndockerCompose { startedServices = listOf(\"postgres\") isRequiredBy(tasks.test) } This approach ensures that tests run against a real PostgreSQL instance, providing confidence that the repository implementations will work correctly in production.\nThe same thing was done in a similar way with RabbitMQ.\n"
            }
        );
    index.add(
            {
                id:  20 ,
                href: "\/docs\/5-implementation\/1-location-service\/",
                title: "Location Service implementation details",
                description: "This chapter provides an overview of the implementation details of the Location Service.\nUser Tracking and Real-time Management linkThe most important and critical feature of the Location Service is the tracking of the user’s location and real-time management of their state considering the high volume of data that needs to be processed in real-time. Moreover, the service is in charge of the user monitoring during the SOS and Routing modes, which require to take real-time actions to ensure the user’s safety.\n",
                content: "This chapter provides an overview of the implementation details of the Location Service.\nUser Tracking and Real-time Management linkThe most important and critical feature of the Location Service is the tracking of the user’s location and real-time management of their state considering the high volume of data that needs to be processed in real-time. Moreover, the service is in charge of the user monitoring during the SOS and Routing modes, which require to take real-time actions to ensure the user’s safety.\nFor what concern the technology stack, the real-time location and user state updates are managed through the WebSocket protocol, which allows bidirectional communication between the client and the service. While this is a common choice for real-time applications and it is well supported by the majority of the programming languages and frameworks, it is worth mentioning that the WebSocket protocol brings with it some challenges in terms of scalability of the service, which is a fundamental requirement for the system. Indeed, each socket connection is bound to a specific instance of the service, which means it is needed to make sure that all the requests from specific users are forwarded to the same instance of the service.\nOne another important aspect to consider is that this service is intrinsically stateful: it needs to keep track of the user’s location and state and take actions based on the history of the past updates and the current state.\nTo address these challenges we adopted a two-level approach. First, the system has been designed and implemented with a fully event-driven approach, starting from the core of the service - the domain - on top of a “event reactions” mechanism. Second, on the technological level, we selected a distributed actor framework based on Akka Cluster thanks to its capabilities to manage and allocate, in a location-transparent way, the actors across the cluster nodes, allowing to scale the service horizontally and to ensure the fault-tolerance of the system.\nFor these reasons the Location Service is implemented in Scala.\nEvent reactions linkThe core of the Location Service is built around the event reactions concept, which represents the actions that the service takes in response to the service driving events.\nThanks to Scala, the event reactions are implemented as ADTs on top of a convenient DSL that allows to define and compose them as a pipeline in a functional way with a “short-circuit” semantic: if one step in the pipeline return a Left outcome (the opposite of a Right outcome) the pipeline stops and the result is returned to the caller. This allows, in the future, to easily extend the pipeline with new steps without changing the existing ones, thus ensuring the extensibility and maintainability of the system.\nThe implemented pipeline is used to react to the DrivingEvents and take appropriate actions to track appropriately the user’s location and state and is compose of the following steps:\nflowchart LR id1(Pre check notifier) id2(Arrival check) id3(Stationary check) id4(Arrival timeout check) id1 --\u003e id2 id2 --\u003e id3 id3 --\u003e id4 Pre check notifier: this steps intercepts valuable events for which a notification has to be sent to the user. Arrival check: this step checks if the user is in routing mode and has arrived at a specific location. Stationary check: this step checks if the user is in routing mode and has become stuck in a specific location. Arrival timeout check: this step checks if the user is in routing mode and has not arrived at the expected destination within the expected time. For example, the following snippet shows the reaction Arrival check reaction implementation:\n/** A [[TrackingEventReaction]] checking if the position curried by the event * is near the arrival position. */ object ArrivalCheck: def apply[F[_]: Async]( using maps: MapsService[F], notifier: NotificationService[F], groups: UserGroupsService[F], ): EventReaction[F] = on[F]: (session, event) =\u003e event match case e: SampledLocation if session.tracking.exists(_.isMonitorable) =\u003e for config \u003c- ReactionsConfiguration.get tracking \u003c- session.tracking.asMonitorable.get.pure[F] distance \u003c- maps.distance(tracking.mode)(e.position, tracking.destination.position) isNear = distance.toMeters.value \u003c= config.proximityToleranceMeters.meters.value _ \u003c- if isNear then sendNotification(session.scope, successMessage) else Async[F].unit yield if isNear then Left(RoutingStopped(e.timestamp, e.scope)) else Right(Continue) case _ =\u003e Right(Continue).pure[F] private val successMessage = notification(\" arrived!\", \" has reached their destination on time.\") They can be composed in a pipeline as follows:\nval reactionPipeline = ( PreCheckNotifier[IO] \u003e\u003e\u003e ArrivalCheck[IO] \u003e\u003e\u003e StationaryCheck[IO] \u003e\u003e\u003e ArrivalTimeoutCheck[IO] )(session, event) Akka Cluster to the rescue linkSince the service should track a large number of users and their tracking information concurrently for each group, the actor model, and in particular, Akka is the perfect fit for this scenario since it can handle smoothly a huge number of actors per node thanks to their very light memory footprint.\nIn particular, the Location Service is implemented using the Akka Cluster Sharding module, which allows to distribute stateful actors across the cluster nodes in a location-transparent way. This means that the service can scale horizontally by adding more nodes to the cluster and the actors will be automatically distributed and, possibly, rebalanced across the nodes without any kind of intervention from the underlying infrastructure. This is possible thanks to the fact the interaction between the actors is guided by their only logical identifier despite their physical location. Moreover, Cluster Sharding entities have a configurable passivation mechanism that allows to automatically stop the actors that are not used for a certain amount of time, thus freeing the resources and ensuring the system’s efficiency.\nAdditionally, the Akka framework support the integration of websockets through the Akka HTTP module, which allows to easily expose the WebSocket endpoints to the clients and to manage the connections and their handlers through actors distributed across the cluster, zeroing the need for additional infrastructure components to deal with scaling and fault-tolerance.\nFor our purposes two main actor entities have been designed:\nRealTimeUserTracker actor which is responsible for managing and tracking a user in real-time in a specific group (recall different group may have different views of the user state and location); GroupManager actor which keeps track of all active websocket connections for a specific group (or, rather, all the actor references of the websocket handlers), acting as a router for the messages between the RealTimeUserTracker actors and the clients. \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e "
            }
        );
    index.add(
            {
                id:  21 ,
                href: "\/docs\/5-implementation\/3-chat-service\/",
                title: "Chat Service implementation details",
                description: "Chat Messaging and Real-time Management linkThe primary functions of the chat service are to manage the chat groups and the relative messages that are exchanged between users of these groups. In most of the cases the amount of messages exchanged is high, and the service needs to manage them in real-time with low latency of response.\nWe built a WebSocket-based communication system using an actor model. Specifically, we leveraged the Event Sourcing module from the Akka framework to handle Group instances. This approach treats Events as first-class citizens while maintaining consistent chat state.\n",
                content: "Chat Messaging and Real-time Management linkThe primary functions of the chat service are to manage the chat groups and the relative messages that are exchanged between users of these groups. In most of the cases the amount of messages exchanged is high, and the service needs to manage them in real-time with low latency of response.\nWe built a WebSocket-based communication system using an actor model. Specifically, we leveraged the Event Sourcing module from the Akka framework to handle Group instances. This approach treats Events as first-class citizens while maintaining consistent chat state.\nWebSockets proved ideal for this use case since each client establishes and maintains an open connection with the server throughout the chat session. This design also addresses scalability concerns, as each connection binds to a specific service instance, ensuring all requests from a user route to the same service instance. To further enhance scalability, we implemented the whole system using Akka Cluster, which allows automatic and trasnparent allocation of actors across cluster nodes, ensuring horizontal scaling and fault tolerance.\nChat Management linkInside the chat system are present two type of actor entities: The GroupEventSourceHandler and the ClientActor. The first one is developed upon the Event Sourcing pattern, the entity it receives commands that represents the actions that can be performed on the group, and emits events that represents changes that have been applied to the group.\nIn the following snippet is shown the implementation that handles a new client joining the group:\nobject GroupEventSourceHandler: def apply(groupId: String): Behavior[Command] = EventSourcedBehavior[Command, Event, State]( persistenceId = PersistenceId(entityKey.name, groupId), emptyState = Group.empty(groupId), commandHandler = commandHandler, eventHandler = eventHandler, ) /** Handle an incoming command from the outside, triggering an event in the domain as response * @param state The actual state of the entity * @param command The received command * @return Return a [[ReplyEffect]] with the response of the operation */ private def commandHandler(state: State, command: Command): Effect[Event, State] = command match case ClientJoinsGroup(clientID, replyTo) =\u003e if state.isPresent(clientID) then Effect.reply(replyTo): StatusReply.Error(CLIENT_ALREADY_JOINED withClientId clientID) else Effect.persist(ClientJoinedToGroup(clientID)).thenReply(replyTo): state =\u003e StatusReply.Success(ClientSuccessfullyJoined(state.clientIDList)) /** Handle a triggered event letting the entity pass to a new state * @param state The actual state of the entity * @param event The triggered event * @return The new state of the entity */ private def eventHandler(state: State, event: Event): State = event match case ClientJoinsGroup(clientID, replyTo) =\u003e if state.isPresent(clientID) then Effect.reply(replyTo): StatusReply.Error(CLIENT_ALREADY_JOINED withClientId clientID) else Effect.persist(ClientJoinedToGroup(clientID)).thenReply(replyTo): state =\u003e StatusReply.Success(ClientSuccessfullyJoined(state.clientIDList)) The ClientActor is instead responsible for managing the communication between the client and the group. It receives messages from the client and forwards them to the group, and vice versa. This entity is created through the webserver when a new connection is established, and is then linked to the GroupEventSourceHandler that manages the group the client is part of. As Akka HTTP is used as the webserver, the ClientActor entity is created using an Akka Stream that allows to handle the WebSocket connection.\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e "
            }
        );
    index.add(
            {
                id:  22 ,
                href: "\/docs\/5-implementation\/2-notification-service\/",
                title: "Notification Service implementation details",
                description: " Currently, the only supported notification types are push notifications, which are essential to guarantee that the client is immediately informed about groups changes or user state changes, like the trigger of the SOS alert or the journey start.\nNotification commands linkLike already presented in the Architecture Design section, the notification service is integrated with the message broker to receive notification commands from other microservices.\n",
                content: " Currently, the only supported notification types are push notifications, which are essential to guarantee that the client is immediately informed about groups changes or user state changes, like the trigger of the SOS alert or the journey start.\nNotification commands linkLike already presented in the Architecture Design section, the notification service is integrated with the message broker to receive notification commands from other microservices.\nIt does this via a durable header-based exchange named push-notifications to which other services can publish the notifications commands presented in the Shared Kernel design section. The notification service is expected to find in the message header the type of the command (i.e. the CommandType in the shared-kernel class diagram) so that it can handle the notification accordingly.\nThe choice of a header-based exchange has been made to allow the notification service to bound multiple queues to the same exchange, each one with a different set of headers, to handle different types of notifications, in a extensible and scalable way. Indeed, looking to extendibility, the notification service can be easily extended to handle new types of notifications by adding new queues bound to the push-notifications exchange, each one with a different set of headers. In fact, the header-based exchange is a type of exchange that routes messages based on the value of the message header. When a message is published to the exchange, the exchange will inspect the header of the message and route it to the queues that are bound to the exchange based on the header values.\ngraph LR subgraph RabbitMQ Broker HeadersExchange[\"Headers Exchange\"] QueuePush[\"Queue: Push Notifications\"] subgraph Future Extension QueueEmail[\"Queue: Email Notifications\"] QueueSMS[\"Queue: SMS Notifications\"] end end Producer[\"Producer: \\n Send Command\"] Microservice[\"Consumer: \\n Notification Microservice\"] Producer -- Publishes Message \\nwith Headers --\u003e HeadersExchange HeadersExchange -- \"x-match: all, type=push, \\n command=GroupWisePushNotification\" --\u003e QueuePush HeadersExchange -- \"x-match: all, type=push, \\n command=CoMembersPushNotification\" --\u003e QueuePush QueuePush --\u003e Microservice HeadersExchange -. \"x-match: all, type=email, \\n command=UserEmailNotification\" .-\u003e QueueEmail HeadersExchange -. \"x-match: all, type=sms, \\n command=UserSMSNotification\" .-\u003e QueueSMS QueueEmail .-\u003e Microservice QueueSMS .-\u003e Microservice The fact the exchange is durable ensures that the exchange will survive a broker restart, and the messages published to it will be persisted until they are delivered to a consumer notification instance.\nPush Notifications linkThe microservice is integrated with Firebase Cloud Messaging (FCM) to send push notifications to the client application.\nFCM is a cross-platform messaging solution provided by Google that enables developers to send notifications and data messages to apps running on iOS, Android, and web platforms. It allows backend services to communicate with client applications by delivering messages efficiently and securely.\nFCM has been chosen over plain WebSockets, which are already used in the system for the real-time tracking of the user’s position, due to several compelling reasons aligned with our specific requirements and infrastructure goals:\nOffline message handling\nOne of the core requirements for the notification service was to ensure message delivery even when users are temporarily offline or the client application is not in foreground.\nFCM natively supports these features: it delivers messages directly to the device’s system tray, allowing users to interact with them to bring the application back to the foreground. If the device is offline, FCM temporarily queues the messages and ensures their delivery as soon as the device reconnects. These features guarantees that users receive all relevant notifications without requiring additional queuing mechanisms.\nScalability and reliability\nFCM is built on Google’s infrastructure, offering seamless scalability without requiring to manage servers, load balancers, or clustering mechanisms. It can handle millions of messages per day effortlessly, with built-in queuing and retry mechanisms for undelivered messages.\nOn the other hand, WebSocket infrastructure demands significant engineering effort to manage load balancing and scaling.\nSecurity and Authentication\nFirebase Cloud Messaging employs OAuth 2.0 for secure authentication of API requests, ensuring that only authorized services can send messages. All communications are encrypted using TLS by default, simplifying compliance with security standards.\nAligned with Use Case: One-Way Notifications\nThe primary function of the notification service is to send one-way notifications from backend systems to users’ devices, not to enable full-duplex communication. FCM is purpose-built for this scenario, providing optimized delivery for both notification messages (visible alerts) and data messages (background processing).\nWhile WebSockets shine in scenarios requiring continuous, bidirectional communication—such as chat apps or live data feeds—they add unnecessary complexity for our needs, where responses from clients are not required.\nLifecycle flow linkThe lifecycle of a push notification message follows these steps:\nThe client app registers the device to FCM, obtaining a registration token that uniquely identifies the app instance. This is direct client app responsibility; The client sends the registration token to the notification service, associating it with the user’s account, through a gRPC API; When a new notification is triggered by one of the other microservices through the message broker, a notification message is composed and sent to the FCM backend using the registration token; The FCM backend delivers the message to the device with the corresponding registration token. In this process, the notification service is responsible for handling the registration and invalidation of device tokens, as well as the composition and delivery of notification messages to the FCM backend.\nNotifications Publisher linkThe logic for sending notifications is encapsulated in the fcm adapter module.\n/** * A notifications publisher sending notifications using Firebase Cloud Messaging. */ class FirebaseCloudNotificationPublisher( private val firebase: Firebase, private val usersTokensRepository: UsersTokensRepository, groupsRepository: GroupsRepository, ) : BasicNotificationPublisher(groupsRepository) { override suspend fun send(message: NotificationMessage, userIds: Set) = userIds.map { usersTokensRepository.get(it) }.forEach { it.mapCatching { userTokens -\u003e userTokens.forEach { userToken -\u003e firebase.sendMessage(userToken.token, message) } }.onFailure { err -\u003e logger.error(\"Failure in sending notification {}: {}\", message, err.message) } } private companion object { private val logger = LoggerFactory.getLogger(this::class.java) } } /** * A Firebase client facade to send notifications. */ class Firebase private constructor(private val app: FirebaseMessaging) { /** * Configuration for the Firebase client. * @property serviceAccountFilePath The absolute path to the service account file. */ data class Configuration( val serviceAccountFilePath: String, ) /** Sends the given [notificationMessage] using the specified [token]. */ fun sendMessage(token: Token, notificationMessage: NotificationMessage) = runCatching { val notification = Notification.builder() .setTitle(notificationMessage.title()) .build() val message = Message.builder() .setNotification(notification) .putData(\"title\", notificationMessage.title()) .putData(\"body\", notificationMessage.body()) .setToken(token) .build() app.send(message) } /** A factory for creating instances of [Firebase]. */ companion object { private const val APP_ID = \"notification-service\" /** Creates a new instance of [Firebase] using the given [configuration]. */ fun create(configuration: Configuration): Result = runCatching { val serviceAccountFilePath = File(configuration.serviceAccountFilePath) .takeIf { it.exists() \u0026\u0026 it.isFile \u0026\u0026 it.extension == \"json\" } ?.absolutePath ?: error(\"${configuration.serviceAccountFilePath} is not present or is not a valid account file!\") val credentials = GoogleCredentials.fromStream(FileInputStream(serviceAccountFilePath)) val options = FirebaseOptions.builder() .setCredentials(credentials) .build() return Result.success(Firebase(FirebaseMessaging.getInstance(FirebaseApp.initializeApp(options, APP_ID)))) } } } API linkThe client can register the device token obtained from FCM to the notification service through a gRPC API, whose protobuf definition is as follows:\nservice UsersTokensService { rpc Register(UserToken) returns (EmptyResponse); rpc Invalidate(UserToken) returns (EmptyResponse); } message UserToken { string user = 1; string token = 2; } message Status { StatusCode code = 1; optional string message = 2; } enum StatusCode { OK = 0; CONFLICT = 1; NOT_FOUND = 2; GENERIC_ERROR = 3; } message EmptyResponse { Status status = 1; } "
            }
        );
    index.add(
            {
                id:  23 ,
                href: "\/docs\/6-validation\/validation\/",
                title: "Self Assessment and Validation",
                description: "Self assessment and validation of the system.",
                content: "Different types of automated tests, at different granularity, are in place to ensure the correctness of the system, as well as the quality of the software product as a whole.\nThe testing strategy follows Martin Fowler’s Test Pyramid idea, which advocates for a higher number of low-level unit tests that are that are fast and cost-effective, complemented by fewer high-level integration and end-to-end tests that, while slower and more complex, validate the overall system’s functionalities.\nEach type of test has been designed and executed accordingly, as detailed in the following sections.\nArchitectural Testing linkArchUnit have been used to enforce architectural constraints, making sure to adhere to the Hexagonal architecture (also known as Onion architecture or Ports and Adapters), preventing unwanted dependencies, maintaining separation of concerns and ensuring architectural decisions are consistently followed over time.\nAn example of arch unit test specification and rules used is shown below and can be found here.\n\"Project-wise architecture\" should \"adhere to ports and adapters, a.k.a onion architecture\" in: val locationGroup = \"io.github.positionpal.location\" val code = ClassFileImporter().importPackages(locationGroup) onionArchitecture() .domainModels(s\"$locationGroup.commons..\", s\"$locationGroup.domain..\") .applicationServices(s\"$locationGroup.application..\", s\"$locationGroup.presentation..\") .adapter(\"real time tracker component\", s\"$locationGroup.tracking..\") .adapter(\"storage\", s\"$locationGroup.storage..\") .adapter(\"message broker\", s\"$locationGroup.messages..\") .adapter(\"gRPC API\", s\"$locationGroup.grpc..\") .adapter(\"web sockets and http web API\", s\"$locationGroup.ws..\") .ignoreDependency(havingEntrypointAsOrigin, andAnyTarget) .because(\"`Entrypoint` submodule contains the main method wiring all the adapters together.\") .ensureAllClassesAreContainedInArchitectureIgnoring(havingEntrypointAsOrigin) .withOptionalLayers(true) .check(code) private def havingEntrypointAsOrigin = DescribedPredicate .describe[JavaClass](\"in `entrypoint` package\", _.getPackage.getName.contains(\"entrypoint\")) private def andAnyTarget = DescribedPredicate.alwaysTrue() This uses the onionArchitecture rule to enforce the following architectural constraints:\nthe domainModels contains all the domain entities and do not depend on any other layer; the applicationServices contains all the application services that are needed to run the application and use cases. They can use and see only the domain models and no other layer; the adapters modules contains logic to connect to external systems and/or infrastructure. They can see and use both the domain models and the application services, but no adapter can depend on another one. the only exception applies to the entrypoint package that contains the main application entrypoint and, thus, need to see and use the various adapters to wire all up together. Unit tests linkUnit tests, which sit at the lowest level of the testing pyramid, focus on verifying that small pieces of code—often individual classes—behave as expected.\nLeveraging testing DSLs frameworks like Kotest and ScalaTest tests can be crafted in a clear and succinct way, enhancing their comprehensibility and maintenance.\nIntegration tests linkVale–\nRequires bring up the single component to test and mock the others…\nEnd-to-End tests linkEnd-to-End tests are the heaviest and slowest tests, as they validate the system as a whole, simulating real user interactions and scenarios.\nThese tests are placed in the access point of the system, i.e., the API gateway, and to be run against the whole system requires the local deployment of all the services along with a mocked version of the client app to make it possible to test real system notifications and interactions in a controlled and repeatable way.\nFor this purpose a local deployment infrastructure has been set up using Docker Compose with a custom template resolution strategy to allow the gateway test lifecycle to:\npackage in a Docker image the gateway service with the latest changes; package the mocked client application in a Docker image; bring up all the system microservices along with the gateway and the mocked client application. With a custom script and a custom option --override we override the default last push image for the gateway service with the local image built in step 1; run the end-to-end tests against the system; tear down the whole system. BeforeAll(async () =\u003e setupLocalDeployment()); AfterAll(async () =\u003e teardownLocalDeployment()); const setupLocalDeployment = () =\u003e { console.log(\"Bring up the local testing environment\"); run(\"docker build --no-cache -t local-gateway .\"); // 1 run(`cd ${mockedAppPath} \u0026\u0026 docker build --no-cache -t mocked-app .`); // 2 run(`${deploymentScript} up --override gateway:local-gateway`); // 3 run(`docker run -d -v ${mockedAppPath}/firebase-config.json:/app/firebase-config.json -p 8080:8080 mocked-app`); // 3 }; const teardownLocalDeployment = () =\u003e { // 5 console.log(\"Tearing down the local testing environment\"); run(`${deploymentScript} down`); run('docker rm $(docker stop $(docker ps -a -q --filter ancestor=mocked-app --format=\"{{.ID}}\"))'); }; const run = (command) =\u003e { /* Run on a shell the given command ... */ }; As presented in the Domain Analysis section, the system has been end-to-end validated and tested using Gherking and Cucumber-JS libraries, along with Puppeteer for browser automation and interactions.\nAn example of a feature implementation is presented hereafter:\nWhen(\"I have arrived at the destination\", async () =\u003e { await this.hanWs.send( JSON.stringify(sample(global.han.userData.id, global.astro.id, cesenaCampusLocation)) ); }); Then(\"the routing is stopped\", { timeout: 20_000 }, async () =\u003e { await eventually(async () =\u003e { expect( receivedUpdates.some((update) =\u003e update.UserUpdate.user === global.han.userData.id \u0026\u0026 update.UserUpdate.status === \"Active\" ), ).to.be.true; }, 15_000); }); Then(\"my state is updated to `Active`\", { timeout: 15_000 }, async () =\u003e { await eventually(async () =\u003e { await expectSuccessfulGetRequest( `/api/session/state/${global.astro.id}/${global.han.userData.id}`, global.han.token, { status: { code: \"OK\" }, state: \"ACTIVE\", }, ); }, 10_000); }); The full suite of end-to-end features and tests can be found here and the report of the last run can be found below:\nStress Test linkStress tests have been performed to evaluate the system’s performance under extreme conditions, such as high loads and peak traffic. These are executed on the production environment, simulating a large number of concurrent users and requests to assess the system’s stability, scalability, and responsiveness.\nIn order to perform these test we used k6, a load testing tool that allows to write test scripts in JavaScript and run them from the command line. In particular we leveraged on xk6, an extended version of k6 that allows to add extension to the tool, in our case we used the Faker extension to generate random data for the tests.\nTest are structured in scenarios that simulate different user behaviors and interactions with the system:\nexport const smokeOptions = { vus: 2, duration: '1m', thresholds: { http_req_duration: ['p(95)\u003c500'], http_req_failed: ['rate\u003c0.01'], }, tags: { test_type: 'smoke' }, }; export const loadOptions = { stages: [ { duration: '2m', target: 50 }, { duration: '5m', target: 50 }, { duration: '2m', target: 0 }, ], thresholds: { http_req_duration: ['p(95)\u003c1000', 'p(99)\u003c1500'], http_req_failed: ['rate\u003c0.05'], }, tags: { test_type: 'load' }, }; export const stressOptions = { stages: [ { duration: '2m', target: 100 }, { duration: '5m', target: 100 }, { duration: '5m', target: 200 }, { duration: '10m', target: 200 }, { duration: '5m', target: 300 }, { duration: '10m', target: 300 }, { duration: '2m', target: 0 }, ], thresholds: { http_req_duration: ['p(95)\u003c2000', 'p(99)\u003c3000'], http_req_failed: ['rate\u003c0.1'], }, tags: { test_type: 'stress' }, }; These scenarios represent three different levels of stress on the system: smoke, load, and stress. The smoke scenario simulates a small number of users and requests, it aims to verify the system’s basic functionalities and responsiveness, the load scenario simulates a medium number of users and requests, simulating the system’s performance under normal conditions while The stress scenario simulates a large number of users and requests verifying the system’s performance under extreme conditions.\nTests are composed of one or more stages where, each of these, represents a different level of stress on the system. Each stage has a duration and a target number of virtual users (VUs) that will be simulated during that stage. The thresholds object contains the performance thresholds that the system must meet during the test, such as the maximum duration of a request or the maximum failure rate.\nQuality Assurance linkFor all the projects and repositories, depending on the language they are developed in, different Quality Assurance (QA) tools have been used to validate the quality of the codebase. These tools ensure adherence to coding standards, maintainability, and early detection of potential issues, if appropriately integrated into Continuous Integration (as per DevOps best practices).\nThe following tools have been used for Scala:\nScalafmt: a code formatter ensuring consistency in code style across the project; Scalafix: a tool for refactoring and linting Scala code, allowing automated fixes for common issues and ensuring best practices. The following tools have been employed for Kotlin:\nktlint: a linter and formatter that enforces Kotlin coding standards automatically; detekt: a static code analysis tool for Kotlin that helps identify code smells, complexity issues, and potential security risks. For Javascript, ESLint, a static analysis tool that enforces coding style rules and detects problematic patterns in JavaScript code.\nTo further improve code quality and reliability, aggressive compilation options have been used across all projects. These options ensure that all warnings are treated as errors, preventing the introduction of potential issues into the codebase. This approach enforces strict compliance with best practices and minimizes the risk of overlooking important warnings that could lead to runtime errors or degraded maintainability.\nBy integrating these QA tools and enforcing strict compilation settings, the project maintains high code quality, reduces technical debt, and ensures consistency across different languages and repositories.\nFor more details on the QA tools and configuration used please refer to the DevOps section.\n"
            }
        );
    index.add(
            {
                id:  24 ,
                href: "\/docs\/7-devops\/devops\/",
                title: "DevOps",
                description: "DevOps practices and tools",
                content: "Build Automation linkSince all microservices are JVM-based (Scala and Kotlin) Gradle have been chosen as the build automation tool.\nRegarding the frontend and the gateway, since they are both written in Javascript, the team has chosen npm as the build automation tool.\nIn the following sections we provide an overview of the relevant configurations and plugins used in the project.\nProjects Structure and shared kernel package linkThe team has decided to implement the microservices using a one-repository-per-service approach, with each service managed as an independent Gradle project, where Gradle sub-projects are used to structure the code, mapping each layer and adapter in the Hexagonal Architecture to a dedicated sub-project.\nThe choice of adopting a one-repository-per-service approach over a mono-repo was made to ensure that each microservice can be developed, tested, and deployed independently from the others, allowing for a more flexible and scalable development process, including a faster build time and CI/CD pipeline execution and an easier management of the codebase dependencies. However, this approach has some drawbacks, such as the need to setup and configure the build tools for each project with a consistent configuration and, especially, how to handle common code across the different microservices.\nThe first problem has been partially mitigated by the use of GitHub Templates, which allowed us to create template repositories with a common structure and configuration that can be used to bootstrap new projects (you can find here the Scala template and here the Kotlin template).\nThe second problem has been faced with the shared kernel. Indeed, code inside the shared kernel must be shared across all the microservices and must be kept in sync with the latest changes. To achieve this, the team has decided to create a separate Gradle project and publish it as a package on a package registry so that it can be included as a normal dependency in all the Gradle builds. Since the code is tightly bound to the project and not intended for public reuse, GitHub Packages was selected as the publishing repository (here the link to the published packages).\nwarning GitHub Packages requires to be authenticated to correctly resolve and download the packages. Developers who intend to build locally the project need to configure their GitHub username and a PAT either in the gradle.properties or as environment variables. Detailed instructions are provided in each microservice README or in the shared-kernel README. Here is an example of how to include the shared kernel in a Gradle project:\nrepositories { mavenCentral() maven { url = uri(\"https://maven.pkg.github.com/position-pal/shared-kernel\") credentials { username = project.findProperty(\"gpr.user\") as String? ?: System.getenv(\"GPR_USER\") password = project.findProperty(\"gpr.key\") as String? ?: System.getenv(\"GPR_KEY\") } } } dependencies { implementation(\"io.github.positionpal:kernel-domain:\") implementation(\"io.github.positionpal:kernel-presentation:\") } Scala Extras Gradle Plugin linkWhile in Kotlin using Gradle is a no-brainer choice and there exist a plethora of plugins and tools to automate the build process, in Scala the situation is a bit different. For this reason, a custom Gradle plugin has been implemented, called Scala Extras to enhance the configuration and build process of all the Scala projects in one place.\nThe plugin, published on Maven Central and on the Gradle Plugin Portal, provides the following features:\nSupport for Scalafix and Scalafmt with a default configuration that can be possibly overridden; Aggressive Scala compiler option to treat warnings as errors is applied by default (still configurable); Out-of-the-box configuration to generate aggregated subprojects scaladoc (which is not supported by the Scala Gradle plugin). By default, applying the plugin to a project is sufficient to enable all the features with the default configuration: in accordance with the standard practices of the Scala community, the plugin will automatically use the .scalafix.conf and/or .scalafmt.conf files if they are present in the root directory of the project. Otherwise, the plugin provides a way to override the default configuration, if needed:\nscalaExtras { qa { allWarningsAsErrors = false scalafix { configFile = \"stringified path to the scalafix configuration\" } scalafmt { configFile = \"stringified path to the scalafmt configuration\" } } } The plugin add the following tasks to the project:\nformat to automatically format the Scala source code adhering to the QA supported tools configuration; aggregateScaladoc to generate the aggregated scaladoc for all the subprojects, including the root one. Moreover, the check task is enhanced to run all the QA tools before the tests, ensuring that the code is compliant with the standards:\nVersion control \u0026 Repository management linkDVCS workflow linkWe have chosen to work with a single stable branch, the main branch, which always contains the latest working version of the code. All development is done in separate branches, such as feature/name for new features, fix/name for bug fixes. Once the changes are ready, they are submitted through pull requests (PRs) to be merged into the main branch. As a team guideline, PRs are rebased on the main branch if it is self-contained and their commits are significant and need to be kept in the history. Otherwise, if the PR is made of many commits (each of which with some experiments) and the history is not relevant, a squash strategy is adopted. No merge commits are allowed in the main branch, since we want to keep the history clean and linear.\nEach pull request is reviewed and must be approved by at least one other developer before it’s merged.\nThe main branch is also where all releases are made, ensuring consistency in the release process.\nCommits are structured following the Conventional Commits standard, which allows for automatic versioning and changelog generation.\nMoreover, all teams members use commit signing to ensure the integrity of the codebase.\nGit hooks linkTo enforce the use of the Conventional Commits standard and Quality Assurance tools (described in the Validation section) each project is equipped with Git hooks that prevent committing code that does not comply with the standards. Where tests are fast the hooks are also configured to run also the tests before the commit. Sometimes, however, repositories contain integration tests that are more time-consuming and would unacceptably slow down the development process. In these cases only the linting and formatting tools are run (along with the Conventional Commits check). This is not a problem since the CI/CD pipeline will run all the tests for each pushed commit, intercepting any possible regression at any time, preventing the main branch from being polluted with broken code.\nBranch Protections linkTo ensure the stability of the main branch, the team has decided to enable the following branch protections:\nRestrict deletions to prevent the main branch from being deleted Require linear history to prevent merge commits from being pushed to the main branch Block force pushes to prevent users from force pushing to the main branch Semantic versioning and release linkEach repository is versioned following the Semantic Versioning standard and is fully automated using Semantic Release. This tool is integrated into the CI/CD pipeline and, after successfully passing the tests, automatically analyzes the commit message to determine whether a new version should be released. If a release is needed, it calculates the new version number, generates the changelog, and creates a new release on GitHub.\nAutomated dependency updates linkTo keep the dependencies up-to-date Renovate has been integrated in every repository and its configuration can be found here.\nSince the Shared Kernel is published as a package on GitHub Packages the following custom hostRule has been added to the configuration to ensure that the Bot is able to look for updates in the correct repository:\n\"hostRules\": [ { \"hostType\": \"maven\", \"matchHost\": \"maven.pkg.github.com\", \"token\": \"{{ secrets.GH_PACKAGES_TOKEN }}\" } ] Moreover, to make sure to trigger a new minor relase when any Position Pal package (including the Shared Kernel) or Docker Image is updated, the following configuration has been added.\n{ \"description\": \"PositionPal packages must be scoped as `api-deps`\", \"matchPackageNames\": [ \"/.*position[-]?pal.*/\" ], \"semanticCommitScope\": \"api-deps\" }, { \"description\": \"Exceptionally, some PositionPal packages should be scoped as normal `deps`\", \"matchPackageNames\": [ \"/.*position[-]?pal\\\\\\/local-deployment.*/\" ], \"semanticCommitScope\": \"deps\" } This will tag the corresponding update commit with api-deps scope, triggering a new minor release by Semantic Release once correctly merged in the main branch. This ensures that the consumers of every Position Pal package and image are always up-to-date with the latest changes.\nContinuous Integration and Delivery linkThe Continuous Integration pipeline of all microservices is described by the following diagram:\ngraph TB; dispatcher([\"0. dispatcher\"]) dispatcher --\u003e build1; dispatcher --\u003e build2; dispatcher --\u003e build3; subgraph 1.matrix-build build1([\"MacOS build\"]); build2([\"Linux build\"]); build3([\"Windows build\"]); build2 --\u003e build4([\"Integration tests\"]); build1 --\u003e build5([\"MacOS fat jar generation\"]); build4 --\u003e build6([\"Linux fat jar generation\"]); build6 --\u003e build8([\"Upload fat jar\"]); build3 --\u003e build7([\"Windows fat jar generation\"]); end dry-delivery([\"2. dry-delivery\"]) build8 --\u003e dry-delivery; build7 --\u003e dry-delivery; build5 --\u003e dry-delivery; release([\"3. release\"]) dry-delivery --\u003e release; publish-images([\"5. publish-images\"]) release --\u003e publish-images; publish-doc([\"4. publish-doc\"]) release --\u003e publish-doc; success([\"6. success\"]) 1.matrix-build .-\u003e success dry-delivery .-\u003e success release .-\u003e success publish-doc --\u003e success publish-images --\u003e success; Dispatcher: the dispatcher is a workflow acting as a filter to ensure that the pipeline runs only when necessary. In particular, it prevents running the entire workflow twice on PRs made by a branch of the same repository, which by default happens when a PR is opened from the repository itself (given both push and pull_request events are triggered).\nBuild: a matrix job that assemble, test and run all checks on the codebase on different platforms (MacOS, Linux, Windows) for different JVM versions (17, 21). Moreover it tries to generate a fat jar for the service and, if successful, it caches it for the next steps in order to speed up the process, avoiding to reassemble the project.\nIf integration tests that require running a Docker service exists, they are only on Linux since the GitHub Actions runner does not support Docker on MacOs and Windows. This is achieved by applying a similar build configuration shown below only to the necessary modules that contain integration tests:\nnormally { dockerCompose { startedServices = listOf(\"cassandra-init\", \"cassandra-db\") isRequiredBy(tasks.test) } } except { inCI and (onMac or onWindows) } where { tasks.test { enabled = false } } cause \"GitHub Actions runner does not support Docker containers\" Dry-delivery: a job that attempts to create a multi-platform docker image out of the generated fat jar.\nRelease: a job that runs the Semantic Release tool to determine if a new version should be released and, if so, it creates a new release on GitHub.\nPublish-doc: a concurrent job that generates the documentation for the project and publishes it on GitHub Pages.\nPublish-images: a concurrent job that publishes the multi-platform docker image on the DockerHub registry.\nSuccess: the final job that runs successfully if all the previous steps have not failed.\nFor the Gateway, a custom pipeline has been designed to take into account the fact that it hosts the end-to-end tests. Indeed, in order to correctly run them, they need to have configured a set of secrets, including the Mapbox API key, the Firebase configuration file and the Akka license key. These are available only in the repository and cannot be used in forks or in PRs from forks to prevent the secrets from being exposed. For this reason, the pipeline is designed to detect if the workflow have access to the required secrets and, if not, it skips the end-to-end tests. In case a PR is opened from a fork, a comment is automatically triggered to warn the contributor a review from a team member is required to validate the changes and then push them to a pre-release branch where the secrets are available and the end-to-end tests can be run. Once also the end-to-end tests are successful, the PR can be merged into the main branch.\nThe modified workflow for the gateway is depicted in the following diagram:\ngraph TB; dispatcher([\"0. dispatcher\"]) dispatcher --\u003e build; detect-secrets([\"1. detect-secrets\"]) build([\"2. Matrix build on MacOS, Linux, Windows\"]) e2e([\"3. End-to-End tests\"]) build --\u003e e2e detect-secrets --\u003e e2e e2e --\u003e dry-delivery dry-delivery([\"2. dry-delivery\"]) release([\"3. release\"]) dry-delivery --\u003e release; publish-images([\"5. publish-images\"]) release --\u003e publish-images; publish-doc([\"4. publish-doc\"]) release --\u003e publish-doc; success([\"6. success\"]) build .-\u003e success e2e .-\u003e success dry-delivery .-\u003e success release .-\u003e success publish-doc --\u003e success publish-images --\u003e success; Additional Bots \u0026 Tools linkMergify linkTo automate the PRs merging process, the Mergify bot has been integrated into the repositories and configured to:\nautomatically request reviews for non-bot PRs; automatically merge PRs authored by a bot if they pass the CI/CD pipeline; automatically and immediately merge PRs that have been approved by at least two reviewers and pass the CI/CD pipeline based on a label that specify the merge strategy (rebase or squash); automatically merge PRs that have been approved by at least one reviewer, pass the CI/CD pipeline and have been unmodified for at least 4 hours; automatically delete branches after the PR has been merged. automatically comment on PRs that have conflicts or do not respect the Conventional Commits standard. Merge protections are in place to ensure merges are performed only when the success job of the CI pipeline is successful, not unresolved conversations are present, and no conflicts are present.\nThe complete configuration can be found here.\nSonarCloud linkWe’ve integrated SonarCloud into our repositories to run automatically within our CI pipeline, in addition to the static quality plugins already integrated into our build tool. This ensures continuous monitoring of code quality, detecting issues such as bugs, code smells, and security vulnerabilities. By identifying bad coding patterns and potential risks early, we enhance maintainability, reduce technical debt, and improve overall software security and reliability.\nContinuous Deployment linkTODO\nLicense linkThe project is licensed under the Apache License 2.0.\n"
            }
        );
    index.add(
            {
                id:  25 ,
                href: "\/docs\/8-deployment\/deployment\/",
                title: "Deployment",
                description: "How we deployed the system on Kubernetes",
                content: "Since our system is composed of multiple microservices, we decided to deploy it on a Kubernetes cluster. Kubernetes is an open-source platform designed to automate deploying, scaling, and operating application containers. It is a powerful tool that allows us to manage our microservices in a more efficient way.\nIn particular the system is mapped on the main abstractions tha kubernetes provides:\nDeployment: A Deployment is a higher-level API object that manages the execution of a set of pods. It provides declarative updates to applications, such as rolling updates, scaling, and pausing and resuming processes. Service: A Service is a resource that provides a stable network endpoint for accessing a set of pods. It acts as an abstraction layer that routes traffic to the appropriate pods, even as pods are created, destroyed, or moved around the cluster. In our cluster we have two types of services: ClusterIP and LoadBalancer. ClusterIP: Exposes the service on a cluster-internal IP. Choosing this value makes the service only reachable from within the cluster. LoadBalancer: Exposes the service externally using a cloud provider’s load balancer. Kubernetes also allows to define other resources that can be used to configure data usage inside the cluster:\nPersistentVolume: A Persistent Volume Claim (PVC) is a request for storage by a user in Kubernetes. It’s similar to how a pod requests CPU and memory resources. PVCs allow users to request specific storage resources (size, access mode) without knowing the details of the underlying storage infrastructure. When a PVC is created, Kubernetes finds an available Persistent Volume (PV) that meets the requirements and binds them together. This provides applications with persistent storage that remains available even if the pod is rescheduled to a different node. ConfigMap: A ConfigMap is an API object used to store non-confidential data in key-value pairs. ConfigMaps allow you to decouple configuration artifacts from image content to keep containerized applications portable. They can be used to store configuration data that can be consumed by pods or used to configure the system. Secret: A Secret is an API object used to store sensitive data, such as passwords, OAuth tokens, and SSH keys. Secrets decouple sensitive information from the pods that use it, and they can be mounted into containers as files or accessed by the Kubernetes API. Architecture overview linkEach microservice is deployed in a separate namespace inside the cluster, this allows to isolate the resources and the network traffic of each service. Each instance then exopose itself, internally, with a service of type ClusterIP that is used by the other services to communicate with it.\nThe architecture of the system is shown below:\nTools used linkThe deployment of the system involves the use of several tools that allow to automate the process of building and deploying the services.\nHelm linkFirst, all services were defined as Helm charts, providing a standardized package management solution for Kubernetes resources. Each microservice is encapsulated in its own chart, complete with templates, values files, and dependencies. This approach enables consistent deployment across environments with simple configuration changes. Helm charts facilitate version control of our infrastructure and simplify rollbacks when needed. Additionally, using Helm allows us to leverage shared libraries and reduce duplication across our Kubernetes manifests.\nThe CI/CD processes ensures to maintain the Helm charts up-to-date with the codebase, so that the deployment process is always consistent with the latest version of the services and, also, allow to deploy the artifacts to the github container registry in order to be used by the kubernetes cluster.\nTerraform linkTo automate the provisioning of the Kubernetes cluster, we used Terraform, an open-source infrastructure as code software tool that provides a consistent CLI workflow to manage cloud services. As we used DigitalOcean as our cloud provider, we leveraged on the terraform provider plugin for describing the infrastructure that should be created.\nIn the main configuration file are defined the resources that should be allocated, like the number of nodes, the type of machine, the region and the k8s version:\nterraform { required_providers { digitalocean = { source = \"digitalocean/digitalocean\" version = \"~\u003e 2.0\" } helm = { source = \"hashicorp/helm\" version = \"~\u003e 2.0\" } } } resource \"digitalocean_kubernetes_cluster\" \"k8s_cluster_do\" { name = var.k8s_clustername region = var.region version = var.k8s_version tags = [\"k8s\"] # This default node pool is mandatory node_pool { name = var.k8s_poolname size = var.size auto_scale = false node_count = var.k8s_count } } Each service then is defined in a separate terraform file, that describes the resources that should be created in the cluster, and the configuration to apply to them. For example, the following snippet shows the definition of the chat service:\nresource \"helm_release\" \"chat_service\" { name = \"chat-service\" repository = \"oci://ghcr.io/position-pal/\" chart = \"position-pal-chat-service\" namespace = \"pp-cs\" version = \"1.4.0\" create_namespace = true set { name = \"rabbitmq.username\" value = var.rabbitmq_username } set { name = \"rabbitmq.password\" value = var.rabbitmq_password } set { name = \"rabbitmq.namespace\" value = \"rabbitmq\" } set { name = \"rabbitmq.serviceName\" value = \"rabbitmq\" } set { name = \"akkaLicenseKey\" value = var.akka_license_key } depends_on = [ helm_release.rabbitmq ] } Is possible to note that is possible to define also the order of the creation of the resources using the depends_on attribute. In this case the chat service depends on the rabbitmq service, so the rabbitmq service is created first. The following diagram shows the deployment order of the services in the cluster:\nflowchart TD subgraph \"Deployment Order\" direction TB k8s[Kubernetes Cluster] --\u003e rabbitmq k8s --\u003e prometheus[Prometheus and Grafana] rabbitmq --\u003e chat_service[Chat Service] rabbitmq --\u003e notification[Notification Service] rabbitmq --\u003e user_service[User Service] rabbitmq --\u003e location_service[Location Service] notification --\u003e Gateway user_service --\u003e Gateway location_service --\u003e Gateway chat_service --\u003e Gateway end classDef default color:black classDef infrastructure fill:#e1f5fe,stroke:#0288d1 classDef messaging fill:#ffecb3,stroke:#ffa000 classDef services fill:#c8e6c9,stroke:#4caf50 classDef entrypoint fill:#f8bbd0,stroke:#e91e63 class k8s infrastructure class rabbitmq messaging class notification,user_service,location_service,chat_service,prometheus services class Gateway entrypoint After creating the infrastructure the first service to be deployed is the rabbitmq service, that is used as a message broker by the other services. Parallelly the monitoring part of the system is deployed, that is composed by the prometheus and grafana services. After that the other services are deployed, that are the chat, notification, user and location services. Finally the gateway service is deployed, that is the entrypoint of the system.\n"
            }
        );
    index.add(
            {
                id:  26 ,
                href: "\/docs\/9-conclusions\/conclusions\/",
                title: "Conclusions",
                description: "Future works link",
                content: "Future works link"
            }
        );
    index.add(
            {
                id:  27 ,
                href: "\/docs\/",
                title: "Docs",
                description: "",
                content: ""
            }
        );
    search.addEventListener('input', show_results, true);

    function show_results(){
        const maxResult =  5 ;
        const minlength =  0 ;
        var searchQuery = sanitizeHTML(this.value);
        var results = index.search(searchQuery, {limit: maxResult, enrich: true});

        
        const flatResults = new Map(); 
        for (const result of results.flatMap(r => r.result)) {
        if (flatResults.has(result.doc.href)) continue;
        flatResults.set(result.doc.href, result.doc);
        }

        suggestions.innerHTML = "";
        suggestions.classList.remove('d-none');

        
        if (searchQuery.length < minlength) {
            const minCharMessage = document.createElement('div')
            minCharMessage.innerHTML = `Please type at least <strong>${minlength}</strong> characters`
            minCharMessage.classList.add("suggestion__no-results");
            suggestions.appendChild(minCharMessage);
            return;
        } else {
            
            if (flatResults.size === 0 && searchQuery) {
                const noResultsMessage = document.createElement('div')
                noResultsMessage.innerHTML = "No results for" + ` "<strong>${searchQuery}</strong>"`
                noResultsMessage.classList.add("suggestion__no-results");
                suggestions.appendChild(noResultsMessage);
                return;
            }
        }

        
        for(const [href, doc] of flatResults) {
            const entry = document.createElement('div');
            suggestions.appendChild(entry);

            const a = document.createElement('a');
            a.href = href;
            entry.appendChild(a);

            const title = document.createElement('span');
            title.textContent = doc.title;
            title.classList.add("suggestion__title");
            a.appendChild(title);

            const description = document.createElement('span');
            description.textContent = doc.description;
            description.classList.add("suggestion__description");
            a.appendChild(description);

            suggestions.appendChild(entry);

            if(suggestions.childElementCount == maxResult) break;
        }
    }
    }());
</script></body></html>